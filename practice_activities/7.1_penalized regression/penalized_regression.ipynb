{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "ames = pd.read_csv(\"data/AmesHousing.csv\")\n",
    "\n",
    "# Get rid of columns with mostly NaN values\n",
    "good_cols = ames.isna().sum() < 100\n",
    "ames = ames.loc[:,good_cols]\n",
    "\n",
    "# Drop other NAs\n",
    "ames = ames.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ames.drop([\"SalePrice\", \"Order\", \"PID\"], axis = 1)\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  #ridge regression where alpha is lambda in the formula\n",
    "  #can put the best alpha and lr_ratio we found from our gridsearch b/c when we gridsearch it overrides whatever we put here\n",
    "  (\"ridge_regression\", Ridge(alpha = 10))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89815807, 0.91744024, 0.79493606, 0.78522563, 0.91389818])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr_pipeline_1, X, y, cv = 5, scoring = 'r2')\n",
    "\n",
    "#scores are way better when using ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss Function**\n",
    "\n",
    "If we use a lot of betas there should be a penalty on the SSR \n",
    "\n",
    "Where the penalty increases as beta get better but the SSR will also go lower \n",
    "\n",
    "Ridge uses this penalty when computing model efficiency -> \"Ridge Penalty\"\n",
    "\n",
    "Penalties calculated using B^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can tune lambdas to test multiple vals\n",
    "lambdas = {\"ridge_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_1, lambdas, cv = 5, scoring='r2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "#gscv_fitted.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ridge_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.864272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.861932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.857773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.856302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.854186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.853920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ridge_regression__alpha    scores\n",
       "4                   10.000  0.864272\n",
       "3                    1.000  0.861932\n",
       "5                  100.000  0.857773\n",
       "2                    0.100  0.856302\n",
       "1                    0.010  0.854186\n",
       "0                    0.001  0.853920"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.90649460e+03,  2.34694314e+03, -1.22917740e+03,  4.62091189e+03,\n",
       "        2.20428500e+03, -3.03646802e+03, -6.17531422e+03,  6.17531422e+03,\n",
       "        2.12575125e+03,  7.53147205e+03, -1.22865537e+04,  2.62933036e+03,\n",
       "       -1.10363100e+04,  9.09887001e+03, -1.49378054e+03,  3.43122056e+03,\n",
       "        2.93687893e+03, -2.42162664e+03, -5.15252289e+02,  1.43157683e+02,\n",
       "        7.56730650e+03, -5.62761832e+03, -2.75896133e+03,  6.76115464e+02,\n",
       "       -3.78227675e+02,  5.60816320e+03, -5.22993552e+03, -3.76824510e+03,\n",
       "        2.45905383e+03,  5.70332014e+03, -6.25300540e+02, -4.25100049e+03,\n",
       "       -8.51682634e+03,  9.07661139e+03, -1.55819272e+04, -1.11163614e+04,\n",
       "        1.72302347e+03,  1.23832549e+04, -6.48871508e+03, -3.70052362e+02,\n",
       "        1.59468710e+03, -1.01764141e+04, -1.10938115e+04,  4.18711022e+03,\n",
       "       -1.32553889e+04,  2.75168983e+04,  2.20925274e+04, -9.78994038e+03,\n",
       "       -7.01890866e+03, -6.59706874e+03, -8.97446647e+03,  9.31639420e+03,\n",
       "        3.08242659e+04, -5.50691247e+03, -3.74580712e+03, -2.09024782e+03,\n",
       "       -4.15882068e+03,  5.95150066e+03,  7.86198989e+03,  5.63755552e+03,\n",
       "       -5.72715772e+03,  5.79895948e+02, -3.48863215e+03, -4.56608363e+03,\n",
       "        1.58213784e+03, -6.81161372e+02,  4.60315253e+02,  1.71248214e+04,\n",
       "       -2.38316196e+04,  3.82518685e+03,  7.48096730e+02,  7.72222929e+02,\n",
       "        7.80002420e+03,  9.63590728e+03, -1.31048959e+02, -1.09431078e+04,\n",
       "       -6.36177473e+03, -2.25720175e+03,  4.35281859e+03,  7.06299725e+03,\n",
       "       -3.55828119e+03, -1.47592254e+03, -7.40577624e+03,  5.06667785e+03,\n",
       "       -1.78531197e+03, -3.18925850e+03,  1.38552638e+03,  1.88637543e+03,\n",
       "        3.17402242e+03, -4.49590735e+03,  1.23924162e+03, -3.93961384e+04,\n",
       "        4.81923172e+03,  2.91083574e+03,  2.12001934e+03,  9.71025350e+02,\n",
       "        1.32845566e+03, -1.61427250e+03,  2.88608431e+04, -9.91657881e+02,\n",
       "        1.48155717e+03,  3.09478907e+03,  1.53258067e+04, -8.95047077e+02,\n",
       "        1.30393099e+02, -4.78573894e+03, -2.22622388e+03,  1.21049017e+01,\n",
       "       -6.95287080e+02,  6.42293426e+03, -1.35945722e+03, -7.68194976e+03,\n",
       "       -4.82070691e+03, -1.32777003e+03, -1.68374647e+03, -2.14412248e+03,\n",
       "        2.73832732e+03,  4.92860925e+02, -2.95569496e+03, -8.95047077e+02,\n",
       "       -1.87922108e+02,  4.95294873e+02,  6.93761781e+03, -1.07594775e+02,\n",
       "       -6.61816732e+02, -2.75504809e+03,  6.42293426e+03, -2.55959490e+03,\n",
       "       -4.19765382e+03,  3.72003353e+03, -1.27480150e+03, -3.06777228e+03,\n",
       "        1.43507471e+04, -6.72275997e+02, -5.30855790e+03, -8.36991325e+03,\n",
       "       -3.25379275e+02, -2.41632895e+03,  1.44466288e+03, -6.25123262e+02,\n",
       "        1.92216860e+03, -2.50152689e+03, -1.04286465e+03,  1.95877716e+03,\n",
       "        4.54716455e+03, -2.96155017e+03,  1.48550520e+04, -2.92502501e+03,\n",
       "       -5.98602580e+03, -7.77091577e+02, -5.16690962e+03, -1.29551376e+03,\n",
       "        6.84932142e+02, -1.14577193e+03,  1.64810533e+03,  1.08248222e+02,\n",
       "        1.40469674e+03,  1.15487314e+04, -6.23671991e+03, -6.71670824e+03,\n",
       "        1.57752933e+03,  4.31511760e+02,  4.58736462e+03, -4.05003108e+03,\n",
       "       -1.58577300e+03, -9.60601630e+02,  4.94927060e+03, -2.89823542e+03,\n",
       "        4.73883934e+03, -4.16797873e+03, -3.22655405e+03,  6.04658258e+02,\n",
       "        2.19424391e+03,  2.53289380e+03,  9.77716879e+02, -5.70485459e+03,\n",
       "        2.99225588e+03, -2.04055198e+03,  1.30217937e+03, -2.46227916e+03,\n",
       "        2.08395896e+02,  1.19546827e+03, -1.19546827e+03,  1.00094048e+02,\n",
       "       -1.03212108e+03,  7.68732872e+02,  3.59129160e+02, -1.95835002e+02,\n",
       "        1.67943514e+04, -5.09487664e+03, -5.90752248e+03,  1.15618305e+03,\n",
       "       -6.94813535e+03, -3.08569285e+03, -5.19773864e+03,  1.70549026e+03,\n",
       "        1.84400630e+03, -3.13147071e+02, -6.57860465e+02, -4.12389611e+03,\n",
       "        9.82883857e+03,  3.43083060e+02, -1.08262982e+03,  7.39546762e+02,\n",
       "       -6.62970133e+03, -6.68693951e+02,  8.56205141e+03,  2.28667988e+03,\n",
       "       -1.83065478e+03, -1.23153676e+03,  2.76382063e+03,  6.65766276e+02,\n",
       "       -8.54325119e+02, -3.06340625e+03, -6.87670759e+03,  5.65611299e+03,\n",
       "        3.71750642e+03, -4.87991998e+03,  2.99321558e+02,  2.08368661e+03,\n",
       "       -4.19282096e+03,  3.55858215e+03,  1.23433686e+04,  5.73295665e+03,\n",
       "        7.02575646e+03,  1.70400603e+03,  2.49840830e+03,  3.09768270e+03,\n",
       "        1.28032656e+03, -1.29071366e+03,  2.62352839e+03,  7.12545811e+03,\n",
       "        1.16770251e+04,  3.94591358e+02,  1.54434008e+04,  2.32016545e+03,\n",
       "       -6.12620144e+02,  2.95929820e+03,  1.93345441e+03, -1.78928648e+03,\n",
       "       -1.99279510e+03,  1.45376703e+03,  2.90720130e+03,  4.58344512e+03,\n",
       "        1.12413499e+03,  1.26683401e+03, -9.16084031e+02,  8.25240406e+02,\n",
       "        1.70889021e+02,  3.10470176e+03,  4.89258612e+02, -4.13548806e+03,\n",
       "       -6.38220273e+02, -9.77427542e+02])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get coefficients of best R^2 model\n",
    "pipeline_fit = lr_pipeline_1.fit(X, y)\n",
    "ridge_coef = pipeline_fit.named_steps[\"ridge_regression\"].coef_\n",
    "ridge_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LASSO**\n",
    "\n",
    "Same penalty as before except penalties calculated using absolute(Betas)\n",
    "\n",
    "consequence: some betas will estimate to be 0 if big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ames.drop([\"SalePrice\", \"Order\", \"PID\"], axis = 1)\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  #ridge regression where alpha is lambda in the formula\n",
    "  #can put the best alpha and lr_ratio we found from our gridsearch b/c when we gridsearch it overrides whatever we put here\n",
    "  (\"lasso_regression\", Lasso(alpha = 100))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can tune lambdas to test multiple vals\n",
    "lambdas = {\"lasso_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_1, lambdas, cv = 5, scoring='r2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.109e+11, tolerance: 1.348e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+11, tolerance: 1.474e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.894e+11, tolerance: 1.463e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e+11, tolerance: 1.407e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.569e+11, tolerance: 1.477e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+11, tolerance: 1.348e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+11, tolerance: 1.474e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+11, tolerance: 1.463e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e+11, tolerance: 1.407e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+11, tolerance: 1.477e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.236e+11, tolerance: 1.348e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e+11, tolerance: 1.474e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+11, tolerance: 1.463e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+11, tolerance: 1.407e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.557e+11, tolerance: 1.477e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.323e+10, tolerance: 1.477e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "#gscv_fitted.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.866931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.860632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.856618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.855606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.855499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lasso_regression__alpha    scores\n",
       "5                  100.000  0.866931\n",
       "4                   10.000  0.860632\n",
       "3                    1.000  0.857152\n",
       "2                    0.100  0.856618\n",
       "1                    0.010  0.855606\n",
       "0                    0.001  0.855499"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -3.40179046e+03, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  2.91561103e+03, -0.00000000e+00,  0.00000000e+00,\n",
       "       -1.02299521e+04,  5.27128450e+03, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        5.35462663e+03, -2.63928711e+03, -0.00000000e+00,  1.77446540e+02,\n",
       "       -0.00000000e+00,  2.11317738e+03, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  2.14107952e+03,  0.00000000e+00,\n",
       "       -0.00000000e+00,  1.41381624e+04, -7.39480667e+03, -1.20939271e+03,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -6.88307419e+02, -3.10766828e+03,  0.00000000e+00,\n",
       "       -4.43798790e+03,  3.63801042e+04,  2.61893814e+04, -2.59146809e+03,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  1.40936035e+04,\n",
       "        3.79963928e+04,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -5.26116157e+02,  6.18676252e+03,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -1.44197439e+04,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        6.39101110e+03,  8.99758270e+03, -0.00000000e+00, -3.73929817e+02,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  2.70465164e+03,\n",
       "       -0.00000000e+00,  0.00000000e+00, -2.05258693e+03,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        1.50311537e+03, -0.00000000e+00, -0.00000000e+00, -2.29884742e+05,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  2.39413389e+04, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.34293214e+04, -0.00000000e+00,\n",
       "        0.00000000e+00, -1.80937496e+03, -0.00000000e+00,  1.96783678e+02,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -6.61730961e+02,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  3.02705176e+02,\n",
       "       -0.00000000e+00, -1.67150210e+03,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  2.35907152e+02, -0.00000000e+00, -0.00000000e+00,\n",
       "        2.11686136e+04,  0.00000000e+00, -0.00000000e+00, -2.48038294e+03,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  2.22939035e+03,\n",
       "        0.00000000e+00, -0.00000000e+00,  2.16416863e+04,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        4.12347823e+03,  1.46867599e+04, -1.53197445e+03, -3.37920142e+03,\n",
       "        2.31536078e+01,  0.00000000e+00,  3.02506204e+03, -9.33738536e+02,\n",
       "       -3.97342731e+02, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -5.77635177e+02, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        2.08603413e+03, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -4.47162942e+01,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        2.28137464e+04,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -1.37207304e+03, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        8.93671126e+03, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -1.56790446e+03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  7.58853576e+03,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -6.73982148e+03,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.53880987e+01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -5.40874122e+03,  3.03464168e+03,  1.22549980e+04,  6.18779549e+03,\n",
       "        8.06375122e+03,  1.83249408e+03,  2.37542355e+03,  5.44070184e+03,\n",
       "        1.19190870e+03, -0.00000000e+00,  2.72268655e+03,  0.00000000e+00,\n",
       "        8.84946221e+02, -7.75650037e+02,  2.59407728e+04,  2.15775117e+03,\n",
       "       -7.10487795e+02,  2.30759686e+03,  1.30396942e+03, -1.84114323e+03,\n",
       "       -1.69775514e+03,  1.03089125e+03,  2.85109699e+03,  3.35600621e+03,\n",
       "        2.24288771e+03,  1.11673375e+03, -6.60358872e+02,  5.94879426e+02,\n",
       "        0.00000000e+00,  2.82988606e+03,  7.91915349e+02, -4.32844378e+03,\n",
       "       -5.76052919e+02, -7.67372632e+02])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get coefficients of best R^2 model\n",
    "pipeline_fit = lr_pipeline_1.fit(X, y)\n",
    "lasso_coef = pipeline_fit.named_steps[\"lasso_regression\"].coef_\n",
    "lasso_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elastic Nets**\n",
    "\n",
    "Inlcudes both penalties when calculating penalty\n",
    "\n",
    "where is still alpha (lambda)\n",
    "\n",
    "and lr_ratio (a) is the ratio between the first degree penalty compared to the second degree penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ames.drop([\"SalePrice\", \"Order\", \"PID\"], axis = 1)\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  #ridge regression where alpha is lambda in the formula\n",
    "  #can put the best alpha and lr_ratio we found from our gridsearch b/c when we gridsearch it overrides whatever we put here\n",
    "  (\"elastic_regression\", ElasticNet(alpha = .01, l1_ratio = .5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can tune lambdas to test multiple vals\n",
    "values = {\"elastic_regression__alpha\": [.001, .01, .1, 1, 10, 100],\n",
    "          \"elastic_regression__l1_ratio\": [.1, .2, .3, .4, .5, .6, .7, .8, .9]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_1, values, cv = 5, scoring='r2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "#gscv_fitted.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elastic_regression__alpha</th>\n",
       "      <th>elastic_regression__l1_ratio</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.864268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.864260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.864214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.864157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.864119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.863994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.863888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.863848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.863687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.863194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.863061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.862904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.862712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.862471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.862155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.861810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.861722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.861085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.860063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.860003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.858404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.858187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.856987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.855718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.854568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.853514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.852539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.851613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.844602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.839357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.834836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.830700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.826789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.823018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.819337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.815716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.811994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.776579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.741137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.706446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.673239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.641903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.612578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.585258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.559864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.534964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.371536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.282009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.226225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.188264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.160798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.140016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.123748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.110670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elastic_regression__alpha  elastic_regression__l1_ratio    scores\n",
       "13                      0.010                           0.5  0.864268\n",
       "14                      0.010                           0.6  0.864260\n",
       "12                      0.010                           0.4  0.864214\n",
       "15                      0.010                           0.7  0.864157\n",
       "11                      0.010                           0.3  0.864119\n",
       "10                      0.010                           0.2  0.863994\n",
       "16                      0.010                           0.8  0.863888\n",
       "9                       0.010                           0.1  0.863848\n",
       "26                      0.100                           0.9  0.863687\n",
       "17                      0.010                           0.9  0.863194\n",
       "0                       0.001                           0.1  0.863061\n",
       "1                       0.001                           0.2  0.862904\n",
       "2                       0.001                           0.3  0.862712\n",
       "3                       0.001                           0.4  0.862471\n",
       "4                       0.001                           0.5  0.862155\n",
       "25                      0.100                           0.8  0.861810\n",
       "5                       0.001                           0.6  0.861722\n",
       "6                       0.001                           0.7  0.861085\n",
       "7                       0.001                           0.8  0.860063\n",
       "24                      0.100                           0.7  0.860003\n",
       "23                      0.100                           0.6  0.858404\n",
       "8                       0.001                           0.9  0.858187\n",
       "22                      0.100                           0.5  0.856987\n",
       "21                      0.100                           0.4  0.855718\n",
       "20                      0.100                           0.3  0.854568\n",
       "19                      0.100                           0.2  0.853514\n",
       "18                      0.100                           0.1  0.852539\n",
       "35                      1.000                           0.9  0.851613\n",
       "34                      1.000                           0.8  0.844602\n",
       "33                      1.000                           0.7  0.839357\n",
       "32                      1.000                           0.6  0.834836\n",
       "31                      1.000                           0.5  0.830700\n",
       "30                      1.000                           0.4  0.826789\n",
       "29                      1.000                           0.3  0.823018\n",
       "28                      1.000                           0.2  0.819337\n",
       "27                      1.000                           0.1  0.815716\n",
       "44                     10.000                           0.9  0.811994\n",
       "43                     10.000                           0.8  0.776579\n",
       "42                     10.000                           0.7  0.741137\n",
       "41                     10.000                           0.6  0.706446\n",
       "40                     10.000                           0.5  0.673239\n",
       "39                     10.000                           0.4  0.641903\n",
       "38                     10.000                           0.3  0.612578\n",
       "37                     10.000                           0.2  0.585258\n",
       "36                     10.000                           0.1  0.559864\n",
       "53                    100.000                           0.9  0.534964\n",
       "52                    100.000                           0.8  0.371536\n",
       "51                    100.000                           0.7  0.282009\n",
       "50                    100.000                           0.6  0.226225\n",
       "49                    100.000                           0.5  0.188264\n",
       "48                    100.000                           0.4  0.160798\n",
       "47                    100.000                           0.3  0.140016\n",
       "46                    100.000                           0.2  0.123748\n",
       "45                    100.000                           0.1  0.110670"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get coefficients of best R^2 model\n",
    "pipeline_fit = lr_pipeline_1.fit(X, y)\n",
    "elastic_coef = pipeline_fit.named_steps[\"elastic_regression\"].coef_\n",
    "elstic_coef"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
