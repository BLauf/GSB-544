{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "#data\n",
    "ames = pd.read_csv('data/AmesHousing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider four possible models for predicting house prices:\n",
    "\n",
    "- Using only the size and number of rooms.\n",
    "- Using size, number of rooms, and building type.\n",
    "- Using size and building type, and their interaction.\n",
    "- Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and also building type.\n",
    "- Set up a pipeline for each of these four models.\n",
    "\n",
    "Then, get predictions on the test set for each of your pipelines, and compute the root mean squared error. Which model performed best?\n",
    "\n",
    "Note: You should only use the function train_test_split() one time in your code; that is, we should be predicting on the same test set for all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1\n",
    "#using only size and num rooms\n",
    "\n",
    "#pick only LotArea and Bedroom\n",
    "#X = ames.drop(\"SalePrice\", axis = 1)\n",
    "X = ames[[\"Lot Area\", \"Bedroom AbvGr\"]]\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    #(\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"Lot Area\", \"Bedroom AbvGr\"])\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DID this for cross_validation only the first 4 models though**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06216223947149311"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model1\n",
    "#using only size and num rooms\n",
    "\n",
    "#pick only LotArea and Bedroom\n",
    "#X = ames.drop(\"SalePrice\", axis = 1)\n",
    "X = ames[[\"Lot Area\", \"Bedroom AbvGr\"]]\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    #(\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"Lot Area\", \"Bedroom AbvGr\"])\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(lr_pipeline_1, X, y, cv=5, scoring='r2')\n",
    "scores.mean()\n",
    "#.062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11087724924265377"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model2\n",
    "#using size, num rooms, building type\n",
    "\n",
    "#pick only LotArea and Bedroom\n",
    "#X = ames.drop(\"SalePrice\", axis = 1)\n",
    "X = ames[[\"Lot Area\", \"Bedroom AbvGr\", \"Bldg Type\"]]\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"Lot Area\", \"Bedroom AbvGr\"])\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "\n",
    "scores = cross_val_score(lr_pipeline_1, X, y, cv=5, scoring='r2')\n",
    "scores.mean()\n",
    "#.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0529075770615026"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model3\n",
    "#using size, building type, interaction\n",
    "\n",
    "#pick only LotArea and Bedroom\n",
    "#X = ames.drop(\"SalePrice\", axis = 1)\n",
    "X = ames[[\"Lot Area\", \"Bldg Type\"]]\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"Lot Area\"])\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "ct_inter = ColumnTransformer(\n",
    "  [\n",
    "    (\"interaction\", PolynomialFeatures(interaction_only = True), [\"standardize__Lot Area\", \"dummify__Bldg Type_1Fam\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ").set_output(transform = \"pandas\")\n",
    "\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"interaction\", ct_inter),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "#check to see what names the transformed variables are\n",
    "#X_train_dummified = ct.fit_transform(X)\n",
    "#X_train_dummified\n",
    "\n",
    "scores = cross_val_score(lr_pipeline_1, X, y, cv=5, scoring='r2')\n",
    "scores.mean()\n",
    "#.052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.2990440872741846"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model4\n",
    "#Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and also building type.\n",
    "\n",
    "#pick only LotArea and Bedroom\n",
    "#X = ames.drop(\"SalePrice\", axis = 1)\n",
    "X = ames[[\"Lot Area\", \"Bedroom AbvGr\", \"Bldg Type\"]]\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"Lot Area\", \"Bedroom AbvGr\"])\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "ct_degree = ColumnTransformer(\n",
    "  [\n",
    "    (\"polynomial_lot\", PolynomialFeatures(degree = 5), [\"standardize__Lot Area\"]),\n",
    "    (\"polynomial_bedroom\", PolynomialFeatures(degree = 5), [\"standardize__Bedroom AbvGr\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ").set_output(transform = \"pandas\")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"poly\", ct_degree),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "#check to see what names the transformed variables are\n",
    "#X_train_dummified = ct.fit_transform(X)\n",
    "#X_train_dummified\n",
    "\n",
    "scores = cross_val_score(lr_pipeline_1, X, y, cv=5, scoring='r2')\n",
    "scores.mean()\n",
    "#2.29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TUNING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice Activity**\n",
    "\n",
    "Consider one hundred modeling options for house price:\n",
    "\n",
    "- House size, trying degrees 1 through 10\n",
    "- Number of rooms, trying degrees 1 through 10\n",
    "- Building Type\n",
    "\n",
    "Hint: The dictionary of possible values that you make to give to GridSearchCV will have two elements instead of one.\n",
    "\n",
    "Q1: Which model performed the best?\n",
    "\n",
    "Q2: What downsides do you see of trying all possible model options? How might you go about choosing a smaller number of tuning values to try?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNING helps us with only degrees, k's, but not recipes or models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = ames[[\"Gr Liv Area\", \"TotRms AbvGrd\", \"Bldg Type\"]]\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "ct_poly = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False), [\"Bldg Type\"]),\n",
    "    (\"polynomial_size\", PolynomialFeatures(), [\"Gr Liv Area\"]),\n",
    "    (\"polynomial_bedroom\", PolynomialFeatures(), [\"TotRms AbvGrd\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "lr_pipeline_poly = Pipeline(\n",
    "  [(\"preprocessing\", ct_poly),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "degrees = {'preprocessing__polynomial_size__degree': np.arange(1, 11),\n",
    "            'preprocessing__polynomial_bedroom__degree': np.arange(1, 11)\n",
    "}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_poly, degrees, cv = 5, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00659461, 0.00404558, 0.00413618, 0.00402522, 0.00425181, 0.00426183,\n",
       "        0.0042942 , 0.00483141, 0.00539985, 0.00511446, 0.00524678, 0.00528231,\n",
       "        0.0063261 , 0.00476565, 0.00736871, 0.0052    , 0.00455866, 0.00510297,\n",
       "        0.00520067, 0.00439715, 0.00339241, 0.00433397, 0.00480828, 0.00767369,\n",
       "        0.00636439, 0.00461025, 0.00400667, 0.00381837, 0.00599322, 0.00656099,\n",
       "        0.0041398 , 0.00637946, 0.00618396, 0.00562372, 0.00575476, 0.00477557,\n",
       "        0.00556078, 0.00520439, 0.00686383, 0.00628133, 0.00677319, 0.00865827,\n",
       "        0.00677218, 0.00876989, 0.00677199, 0.00449767, 0.00603328, 0.00535641,\n",
       "        0.00792041, 0.00907955, 0.00610485, 0.00637727, 0.00700431, 0.00537744,\n",
       "        0.00547442, 0.00649757, 0.00619912, 0.01041174, 0.00929785, 0.00632377,\n",
       "        0.00802345, 0.01546564, 0.01097784, 0.00706892, 0.01011806, 0.01032653,\n",
       "        0.0099277 , 0.00794578, 0.00625582, 0.00592675, 0.00547743, 0.00699229,\n",
       "        0.00624247, 0.00458026, 0.00535679, 0.0055088 , 0.00641694, 0.0060904 ,\n",
       "        0.00564718, 0.00455365, 0.00470057, 0.00667982, 0.00384126, 0.0065414 ,\n",
       "        0.0064651 , 0.00726075, 0.00654283, 0.01097488, 0.00657153, 0.00935087,\n",
       "        0.00957251, 0.01381125, 0.00653582, 0.00714226, 0.00911093, 0.01019988,\n",
       "        0.00844817, 0.00572586, 0.00558734, 0.01086369]),\n",
       " 'std_fit_time': array([3.62172708e-03, 7.08789214e-04, 5.21449429e-04, 7.13429982e-04,\n",
       "        7.01943729e-04, 5.99777552e-04, 6.04437029e-04, 1.46289332e-03,\n",
       "        1.66803097e-03, 1.37724997e-03, 1.79825099e-03, 1.59825899e-03,\n",
       "        2.19959824e-03, 1.17538406e-03, 1.85795766e-03, 1.75682523e-03,\n",
       "        1.50534675e-03, 1.18155223e-03, 2.31436864e-03, 8.36489742e-04,\n",
       "        4.01230631e-05, 1.59702487e-03, 1.35498366e-03, 2.59386614e-03,\n",
       "        2.37949637e-03, 1.04019961e-03, 5.09282877e-04, 3.12345431e-04,\n",
       "        2.50053095e-03, 2.67151830e-03, 1.23172683e-03, 2.21001853e-03,\n",
       "        4.20321601e-03, 1.56653930e-03, 1.99788788e-03, 1.58471739e-03,\n",
       "        1.50924157e-03, 9.47196194e-04, 2.79616640e-03, 3.22996845e-03,\n",
       "        5.83843088e-03, 3.19975668e-03, 2.49628561e-03, 4.20226509e-03,\n",
       "        2.44912738e-03, 1.28717336e-03, 3.53186621e-03, 2.71608868e-03,\n",
       "        2.76462602e-03, 4.55245614e-03, 3.19690347e-03, 3.12469772e-03,\n",
       "        2.25574615e-03, 1.73036518e-03, 9.25124041e-04, 2.92745383e-03,\n",
       "        2.21603615e-03, 2.02000570e-03, 3.26613069e-03, 3.80535815e-03,\n",
       "        3.60482935e-03, 1.39835914e-02, 5.44844833e-03, 3.32024487e-03,\n",
       "        6.37418688e-03, 4.29676625e-03, 3.56543668e-03, 1.65922544e-03,\n",
       "        1.80699416e-03, 3.43962853e-03, 2.30657642e-03, 3.76100984e-03,\n",
       "        3.03601246e-03, 1.70599532e-03, 2.21747415e-03, 2.32878807e-03,\n",
       "        2.32781407e-03, 3.41596875e-03, 1.49127703e-03, 4.90564998e-04,\n",
       "        1.66309315e-03, 3.13434698e-03, 1.09570663e-04, 2.46440052e-03,\n",
       "        2.99978320e-03, 2.36248338e-03, 2.14094711e-03, 1.99286284e-03,\n",
       "        2.00794308e-03, 3.92541875e-03, 2.89347034e-03, 1.09936811e-02,\n",
       "        2.24589839e-03, 1.62076788e-03, 3.48032518e-03, 3.03119437e-03,\n",
       "        2.99361818e-03, 1.48783236e-03, 1.58696195e-03, 3.78327768e-03]),\n",
       " 'mean_score_time': array([0.00354738, 0.00207663, 0.00218096, 0.00215826, 0.00239677, 0.00243583,\n",
       "        0.00229478, 0.00226841, 0.00346594, 0.00268989, 0.00438418, 0.00351229,\n",
       "        0.00278087, 0.00205564, 0.00401273, 0.00391517, 0.00237241, 0.00214081,\n",
       "        0.00208416, 0.00380492, 0.00195966, 0.00267262, 0.00315466, 0.00362759,\n",
       "        0.00362301, 0.00307698, 0.00348034, 0.00220714, 0.00300422, 0.00466456,\n",
       "        0.00237951, 0.00542364, 0.00361481, 0.00320382, 0.00607233, 0.00409713,\n",
       "        0.00345421, 0.00382586, 0.0052052 , 0.00322251, 0.00265121, 0.00600266,\n",
       "        0.00352979, 0.00545216, 0.00229535, 0.00286183, 0.00428095, 0.00205836,\n",
       "        0.00454016, 0.00362716, 0.00293398, 0.00322523, 0.00338864, 0.0037231 ,\n",
       "        0.00488801, 0.00554299, 0.00475874, 0.00671244, 0.00583801, 0.00340228,\n",
       "        0.00308013, 0.00450373, 0.00502644, 0.00419884, 0.00802345, 0.00674205,\n",
       "        0.00703907, 0.00465927, 0.00371294, 0.00311561, 0.00213737, 0.00235171,\n",
       "        0.00395856, 0.00208693, 0.00328922, 0.00271096, 0.00432615, 0.00326834,\n",
       "        0.00250983, 0.00210238, 0.00274568, 0.00293927, 0.00274873, 0.00443492,\n",
       "        0.00351429, 0.00429907, 0.00384583, 0.00413098, 0.00609403, 0.0045711 ,\n",
       "        0.00471325, 0.008673  , 0.00327907, 0.00449238, 0.00558   , 0.00423307,\n",
       "        0.00670457, 0.00340047, 0.00329127, 0.00521669]),\n",
       " 'std_score_time': array([9.94063459e-04, 1.26986042e-04, 3.80391134e-04, 1.42179184e-04,\n",
       "        6.40005416e-04, 5.85528200e-04, 2.77087812e-04, 3.94077095e-04,\n",
       "        1.70641998e-03, 1.12611973e-03, 2.54410892e-03, 1.66916724e-03,\n",
       "        1.47368907e-03, 8.05455453e-05, 2.33485568e-03, 2.97491433e-03,\n",
       "        2.65318622e-04, 2.54887343e-04, 1.00099534e-04, 2.08676085e-03,\n",
       "        9.03218949e-05, 1.48598741e-03, 1.49649402e-03, 1.64240357e-03,\n",
       "        1.77682895e-03, 1.84020150e-03, 1.62500655e-03, 2.15338446e-04,\n",
       "        1.93667388e-03, 1.51505665e-03, 8.88072904e-04, 3.17975780e-03,\n",
       "        1.86677968e-03, 1.15316698e-03, 3.03109833e-03, 2.52431330e-03,\n",
       "        1.86782228e-03, 2.16836777e-03, 2.40770460e-03, 1.54729936e-03,\n",
       "        1.12621535e-03, 2.44045270e-03, 1.27859509e-03, 1.20678792e-03,\n",
       "        2.26225670e-04, 1.36399114e-03, 1.92071728e-03, 1.21188762e-04,\n",
       "        2.07165192e-03, 1.53538063e-03, 1.94327800e-03, 1.75316267e-03,\n",
       "        2.26382071e-03, 2.98256084e-03, 2.20791906e-03, 1.00410045e-03,\n",
       "        1.30124417e-03, 1.52492476e-03, 2.20173908e-03, 1.29305682e-03,\n",
       "        1.57179677e-03, 3.07965616e-03, 3.21797268e-03, 1.48777645e-03,\n",
       "        6.36210532e-03, 3.41193803e-03, 2.88138682e-03, 1.89775079e-03,\n",
       "        1.43958940e-03, 1.98743384e-03, 2.22891938e-04, 5.75307448e-04,\n",
       "        2.46592691e-03, 2.41252149e-04, 1.61527362e-03, 7.32083581e-04,\n",
       "        1.99661718e-03, 1.35340666e-03, 9.26809078e-04, 9.80318519e-05,\n",
       "        1.13349446e-03, 8.26671423e-04, 1.52100679e-03, 2.88153720e-03,\n",
       "        1.23839051e-03, 1.88219570e-03, 1.38864874e-03, 1.20861139e-03,\n",
       "        1.75581529e-03, 2.49659205e-03, 2.40331271e-03, 6.65359216e-03,\n",
       "        1.72412584e-03, 2.16126796e-03, 2.12480581e-03, 2.66220882e-03,\n",
       "        2.26951980e-03, 1.47774785e-03, 2.32677251e-03, 2.58513340e-03]),\n",
       " 'param_preprocessing__polynomial_bedroom__degree': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocessing__polynomial_size__degree': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                    9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7,\n",
       "                    8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6,\n",
       "                    7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5,\n",
       "                    6, 7, 8, 9, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 10}],\n",
       " 'split0_test_score': array([0.53197809, 0.53171602, 0.54522355, 0.54379565, 0.50847886, 0.50803388,\n",
       "        0.50404864, 0.48824759, 0.45353318, 0.40231935, 0.52048972, 0.52917544,\n",
       "        0.53566999, 0.53571259, 0.50847886, 0.50803388, 0.50404864, 0.48824759,\n",
       "        0.45353318, 0.40231935, 0.5242219 , 0.53081818, 0.53590891, 0.5362294 ,\n",
       "        0.50158162, 0.50803388, 0.50404864, 0.48824759, 0.45353318, 0.40231935,\n",
       "        0.53184271, 0.53758574, 0.53945895, 0.53883862, 0.50037316, 0.50803388,\n",
       "        0.50404864, 0.48824759, 0.45353318, 0.40231935, 0.5319609 , 0.53735141,\n",
       "        0.53930072, 0.53887791, 0.50052242, 0.50803388, 0.50404864, 0.48824759,\n",
       "        0.45353318, 0.40231935, 0.53190067, 0.53745662, 0.53938499, 0.53869032,\n",
       "        0.50565347, 0.50164211, 0.50404864, 0.48824759, 0.45353318, 0.40231935,\n",
       "        0.53133617, 0.53727551, 0.54040972, 0.53917886, 0.50525067, 0.50358824,\n",
       "        0.50404864, 0.48824759, 0.45353318, 0.40231935, 0.53065114, 0.53658738,\n",
       "        0.54022423, 0.53965147, 0.50604541, 0.4977158 , 0.50404864, 0.48824759,\n",
       "        0.45353318, 0.40231935, 0.53099301, 0.536678  , 0.54059691, 0.53952784,\n",
       "        0.50739353, 0.49827708, 0.50404864, 0.48824759, 0.45353318, 0.40231918,\n",
       "        0.53012521, 0.53588315, 0.5399751 , 0.54002034, 0.50734457, 0.50007613,\n",
       "        0.50375315, 0.48824759, 0.45353355, 0.40231918]),\n",
       " 'split1_test_score': array([0.53225302, 0.52618888, 0.53488419, 0.53516783, 0.45451042, 0.45231332,\n",
       "        0.44389116, 0.42226201, 0.38464169, 0.33730999, 0.53730671, 0.51997812,\n",
       "        0.53893103, 0.53781855, 0.45451042, 0.45231332, 0.44389116, 0.42226201,\n",
       "        0.38464169, 0.33730999, 0.5354238 , 0.52445722, 0.53895206, 0.53749177,\n",
       "        0.49887582, 0.45231332, 0.44389116, 0.42226201, 0.38464169, 0.33730999,\n",
       "        0.53544608, 0.52151401, 0.53586828, 0.53487707, 0.4983378 , 0.45231332,\n",
       "        0.44389116, 0.42226201, 0.38464169, 0.33730999, 0.53500045, 0.52031442,\n",
       "        0.53451754, 0.53353129, 0.49889726, 0.45231332, 0.44389116, 0.42226201,\n",
       "        0.38464169, 0.33730999, 0.53504   , 0.5213231 , 0.53534431, 0.53373064,\n",
       "        0.49114728, 0.49100047, 0.44389116, 0.42226201, 0.38464169, 0.33730999,\n",
       "        0.53405576, 0.52000604, 0.5331316 , 0.53400577, 0.48943155, 0.48652811,\n",
       "        0.44389116, 0.42226201, 0.38464169, 0.33730999, 0.53534435, 0.52030135,\n",
       "        0.53172174, 0.53048616, 0.49175656, 0.49273121, 0.44389116, 0.42226201,\n",
       "        0.38464169, 0.33730999, 0.53255867, 0.52045329, 0.53188811, 0.53027031,\n",
       "        0.49245972, 0.4899853 , 0.44389113, 0.42226201, 0.38464169, 0.33731018,\n",
       "        0.51743415, 0.50853845, 0.52381461, 0.53062884, 0.49127565, 0.48670151,\n",
       "        0.47003606, 0.42226201, 0.38464169, 0.33731018]),\n",
       " 'split2_test_score': array([ 4.28295335e-01,  4.56095393e-01,  5.12144051e-01,  4.61596230e-01,\n",
       "         1.73388201e-01, -3.94185115e-01, -1.67096399e+00, -4.78706736e+00,\n",
       "        -1.26045513e+01, -3.20376683e+01,  4.34384984e-01,  4.51860030e-01,\n",
       "         5.12220963e-01,  4.70621944e-01,  1.73388200e-01, -3.94185115e-01,\n",
       "        -1.67096399e+00, -4.78706730e+00, -1.26045513e+01, -3.20376683e+01,\n",
       "         4.37847834e-01,  4.43445488e-01,  5.04808139e-01,  4.78667699e-01,\n",
       "         3.49256420e-01, -3.94185115e-01, -1.67096399e+00, -4.78706730e+00,\n",
       "        -1.26045513e+01, -3.20376683e+01,  4.22601291e-01,  4.18640590e-01,\n",
       "         4.72190028e-01,  4.99580538e-01,  3.25875236e-01, -3.94185115e-01,\n",
       "        -1.67096399e+00, -4.78706730e+00, -1.26045513e+01, -3.20376683e+01,\n",
       "         4.19178646e-01,  4.09008772e-01,  4.63061320e-01,  4.99862050e-01,\n",
       "         3.18007628e-01, -3.94185098e-01, -1.67096399e+00, -4.78706730e+00,\n",
       "        -1.26045513e+01, -3.20376683e+01,  4.19085877e-01,  4.09765911e-01,\n",
       "         4.66764739e-01,  4.99052854e-01,  4.36673847e-01,  2.77488562e-01,\n",
       "        -1.67096399e+00, -4.78706730e+00, -1.26045513e+01, -3.20376683e+01,\n",
       "         4.19064840e-01,  4.09793877e-01,  4.72075883e-01,  4.85925311e-01,\n",
       "         4.54114081e-01,  3.12566528e-01, -1.67096399e+00, -4.78706730e+00,\n",
       "        -1.26045513e+01, -3.20376683e+01,  4.19415300e-01,  4.09770612e-01,\n",
       "         4.69446754e-01,  4.79923869e-01,  1.90109695e-01, -3.76863379e-01,\n",
       "        -1.67096389e+00, -4.78706730e+00, -1.26045513e+01, -3.20376683e+01,\n",
       "         4.21259340e-01,  4.11189150e-01,  4.70211810e-01,  4.82802626e-01,\n",
       "        -5.35651830e-02, -5.21516642e-01, -3.13753366e-03, -4.78706730e+00,\n",
       "        -1.26045513e+01, -3.20376514e+01,  4.21475224e-01,  4.11558859e-01,\n",
       "         4.70247122e-01,  4.86811347e-01, -1.43811899e-01, -1.64240307e-01,\n",
       "        -3.58627508e-02, -4.78706731e+00, -1.26045604e+01, -3.20376514e+01]),\n",
       " 'split3_test_score': array([ 5.65747933e-01,  5.82384226e-01,  5.92700784e-01,  5.98211999e-01,\n",
       "         5.47422750e-01,  5.32731294e-01,  3.13703418e-01, -1.49591606e+00,\n",
       "        -1.14656224e+01, -5.01071068e+01,  5.71443248e-01,  5.75605343e-01,\n",
       "         5.95944662e-01,  6.00604937e-01,  5.47422750e-01,  5.32731294e-01,\n",
       "         3.13703418e-01, -1.49591595e+00, -1.14656224e+01, -5.01071068e+01,\n",
       "         5.88074536e-01,  5.83533300e-01,  5.90476921e-01,  5.94607946e-01,\n",
       "         5.78123862e-01,  5.32731294e-01,  3.13703418e-01, -1.49591595e+00,\n",
       "        -1.14656224e+01, -5.01071068e+01,  6.15356800e-01,  6.03073637e-01,\n",
       "         6.00342961e-01,  6.03074113e-01,  5.65100471e-01,  5.32731294e-01,\n",
       "         3.13703418e-01, -1.49591595e+00, -1.14656224e+01, -5.01071068e+01,\n",
       "         6.16704667e-01,  5.89473109e-01,  5.92295885e-01,  6.02401904e-01,\n",
       "         5.50867548e-01,  5.32731294e-01,  3.13703418e-01, -1.49591595e+00,\n",
       "        -1.14656224e+01, -5.01071068e+01,  5.85729787e-01,  6.02705181e-01,\n",
       "         5.80443227e-01,  5.86263815e-01,  5.75908441e-01,  5.80254956e-01,\n",
       "         3.13703418e-01, -1.49591595e+00, -1.14656224e+01, -5.01071068e+01,\n",
       "        -1.68548642e+00, -2.99315879e-01,  9.10996430e-02,  6.02921498e-01,\n",
       "         5.38009476e-01,  5.77098810e-01,  3.13703418e-01, -1.49591595e+00,\n",
       "        -1.14656224e+01, -5.01071068e+01, -7.53704629e+00, -2.94565108e+00,\n",
       "         2.35021598e-03, -7.66536116e-01,  3.89333496e-01,  3.65119026e-01,\n",
       "         3.13703405e-01, -1.49591595e+00, -1.14656224e+01, -5.01071068e+01,\n",
       "        -7.35541490e-01,  3.93171850e-01, -7.37209345e+00, -1.96054718e+00,\n",
       "         5.47489842e-01,  2.46906460e-01,  3.13703471e-01, -1.49591595e+00,\n",
       "        -1.14656224e+01, -5.01068956e+01, -9.23176290e+02, -9.49419000e+02,\n",
       "        -1.98181880e+03, -2.72789891e+00,  7.90393532e-02, -1.14297191e+00,\n",
       "         4.99619841e-01, -1.49591595e+00, -1.14657339e+01, -5.01068956e+01]),\n",
       " 'split4_test_score': array([0.60613781, 0.59097517, 0.60325039, 0.60835332, 0.57550038, 0.5702938 ,\n",
       "        0.55592936, 0.53199328, 0.50402512, 0.46569119, 0.59828957, 0.59121783,\n",
       "        0.60151955, 0.60609193, 0.57550038, 0.5702938 , 0.55592936, 0.53199328,\n",
       "        0.50402512, 0.46569119, 0.59405278, 0.58841648, 0.60004926, 0.60520428,\n",
       "        0.59830952, 0.5702938 , 0.55592936, 0.53199328, 0.50402512, 0.46569119,\n",
       "        0.60239686, 0.59627402, 0.6041018 , 0.60793042, 0.59332897, 0.5702938 ,\n",
       "        0.55592936, 0.53199328, 0.50402512, 0.46569119, 0.60248625, 0.59518882,\n",
       "        0.60357003, 0.60767191, 0.595177  , 0.5702938 , 0.55592936, 0.53199328,\n",
       "        0.50402512, 0.46569119, 0.60255496, 0.59531701, 0.60391651, 0.60742242,\n",
       "        0.60274672, 0.58205813, 0.55592936, 0.53199328, 0.50402512, 0.46569119,\n",
       "        0.60137637, 0.59473349, 0.60528089, 0.60843503, 0.60245949, 0.57970194,\n",
       "        0.55592936, 0.53199328, 0.50402512, 0.46569119, 0.60019991, 0.59380085,\n",
       "        0.60476946, 0.60850058, 0.60202347, 0.58127184, 0.55592936, 0.53199328,\n",
       "        0.50402512, 0.46569119, 0.60150623, 0.59488935, 0.60575142, 0.60843174,\n",
       "        0.60374367, 0.57843237, 0.55592936, 0.53199328, 0.50402512, 0.46569206,\n",
       "        0.60120898, 0.59481444, 0.6048011 , 0.60892435, 0.60362811, 0.59049255,\n",
       "        0.56298264, 0.53199328, 0.50402514, 0.46569206]),\n",
       " 'mean_test_score': array([ 5.32882439e-01,  5.37471938e-01,  5.57640592e-01,  5.49425004e-01,\n",
       "         4.51860122e-01,  3.33837437e-01,  2.93217204e-02, -9.68096108e-01,\n",
       "        -4.54559475e+00, -1.61878909e+01,  5.32382847e-01,  5.33567353e-01,\n",
       "         5.56857238e-01,  5.50169989e-01,  4.51860121e-01,  3.33837437e-01,\n",
       "         2.93217204e-02, -9.68096074e-01, -4.54559475e+00, -1.61878909e+01,\n",
       "         5.35924169e-01,  5.34134134e-01,  5.54039055e-01,  5.50440217e-01,\n",
       "         5.05229447e-01,  3.33837437e-01,  2.93217204e-02, -9.68096074e-01,\n",
       "        -4.54559475e+00, -1.61878909e+01,  5.41528749e-01,  5.35417599e-01,\n",
       "         5.50392405e-01,  5.56860152e-01,  4.96603128e-01,  3.33837437e-01,\n",
       "         2.93217204e-02, -9.68096074e-01, -4.54559475e+00, -1.61878909e+01,\n",
       "         5.41066183e-01,  5.30267305e-01,  5.46549098e-01,  5.56469011e-01,\n",
       "         4.92694372e-01,  3.33837440e-01,  2.93217204e-02, -9.68096074e-01,\n",
       "        -4.54559475e+00, -1.61878909e+01,  5.34862257e-01,  5.33313563e-01,\n",
       "         5.45170756e-01,  5.53032010e-01,  5.22425951e-01,  4.86488846e-01,\n",
       "         2.93217204e-02, -9.68096074e-01, -4.54559475e+00, -1.61878909e+01,\n",
       "         8.00693446e-02,  3.52498608e-01,  4.48399545e-01,  5.54093295e-01,\n",
       "         5.17853052e-01,  4.91896725e-01,  2.93217203e-02, -9.68096074e-01,\n",
       "        -4.54559475e+00, -1.61878909e+01, -1.09028712e+00, -1.77038177e-01,\n",
       "         4.29702480e-01,  2.78405193e-01,  4.35853727e-01,  3.11994900e-01,\n",
       "         2.93217363e-02, -9.68096074e-01, -4.54559475e+00, -1.61878909e+01,\n",
       "         2.70155151e-01,  4.91276328e-01, -1.04472904e+00,  4.00970687e-02,\n",
       "         4.19504316e-01,  2.58416913e-01,  3.62887011e-01, -9.68096074e-01,\n",
       "        -4.54559475e+00, -1.61878451e+01, -1.84221209e+02, -1.89473641e+02,\n",
       "        -3.95935992e+02, -1.12302808e-01,  3.07495156e-01,  5.40115945e-02,\n",
       "         4.00105788e-01, -9.68096076e-01, -4.54561878e+00, -1.61878451e+01]),\n",
       " 'std_test_score': array([5.89680705e-02, 4.82955255e-02, 3.47892014e-02, 5.25386860e-02,\n",
       "        1.45036854e-01, 3.66024084e-01, 8.53978163e-01, 2.05754398e+00,\n",
       "        6.12585890e+00, 2.11063393e+01, 5.59261703e-02, 4.89301804e-02,\n",
       "        3.54547430e-02, 4.97200431e-02, 1.45036855e-01, 3.66024084e-01,\n",
       "        8.53978163e-01, 2.05754395e+00, 6.12585890e+00, 2.11063393e+01,\n",
       "        5.63112009e-02, 5.23754136e-02, 3.58459471e-02, 4.57619818e-02,\n",
       "        8.75885327e-02, 3.66024084e-01, 8.53978163e-01, 2.05754395e+00,\n",
       "        6.12585890e+00, 2.11063393e+01, 6.84544620e-02, 6.65067276e-02,\n",
       "        4.86330335e-02, 4.20306755e-02, 9.29655964e-02, 3.66024084e-01,\n",
       "        8.53978163e-01, 2.05754395e+00, 6.12585890e+00, 2.11063393e+01,\n",
       "        6.99569522e-02, 6.71907829e-02, 5.00233186e-02, 4.18843673e-02,\n",
       "        9.43419526e-02, 3.66024077e-01, 8.53978163e-01, 2.05754395e+00,\n",
       "        6.12585890e+00, 2.11063393e+01, 6.41603923e-02, 6.94040085e-02,\n",
       "        4.68460200e-02, 3.88706740e-02, 5.98746972e-02, 1.11226496e-01,\n",
       "        8.53978163e-01, 2.05754395e+00, 6.12585890e+00, 2.11063393e+01,\n",
       "        8.84715945e-01, 3.31368030e-01, 1.83565213e-01, 4.60652587e-02,\n",
       "        5.01872264e-02, 9.72563457e-02, 8.53978164e-01, 2.05754395e+00,\n",
       "        6.12585890e+00, 2.11063393e+01, 3.22390354e+00, 1.38559003e+00,\n",
       "        2.17936229e-01, 5.24074329e-01, 1.40156087e-01, 3.51287871e-01,\n",
       "        8.53978125e-01, 2.05754395e+00, 6.12585890e+00, 2.11063393e+01,\n",
       "        5.06150914e-01, 7.70541503e-02, 3.16397383e+00, 1.00112645e+00,\n",
       "        2.39652328e-01, 4.05461601e-01, 2.00073290e-01, 2.05754395e+00,\n",
       "        6.12585890e+00, 2.11062690e+01, 3.69477545e+02, 3.79972684e+02,\n",
       "        7.92941405e+02, 1.30838343e+00, 2.88887485e-01, 6.56415927e-01,\n",
       "        2.20060674e-01, 2.05754395e+00, 6.12588653e+00, 2.11062690e+01]),\n",
       " 'rank_test_score': array([ 23,  16,   1,  11,  34,  46,  58,  75,  78,  97,  24,  21,   3,  10,\n",
       "         35,  47,  61,  66,  80,  90,  17,  20,   6,   8,  28,  45,  60,  66,\n",
       "         80,  90,  14,  18,   9,   2,  29,  44,  62,  66,  80,  90,  15,  25,\n",
       "         12,   4,  30,  43,  59,  70,  80,  90,  19,  22,  13,   7,  26,  33,\n",
       "         57,  69,  80,  90,  53,  42,  36,   5,  27,  31,  63,  71,  80,  90,\n",
       "         77,  65,  38,  50,  37,  48,  56,  72,  86,  90,  51,  32,  76,  55,\n",
       "         39,  52,  41,  73,  79,  88,  98,  99, 100,  64,  49,  54,  40,  74,\n",
       "         87,  88], dtype=int32)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "gscv_fitted.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00659461, 0.00404558, 0.00413618, 0.00402522, 0.00425181, 0.00426183,\n",
       "        0.0042942 , 0.00483141, 0.00539985, 0.00511446, 0.00524678, 0.00528231,\n",
       "        0.0063261 , 0.00476565, 0.00736871, 0.0052    , 0.00455866, 0.00510297,\n",
       "        0.00520067, 0.00439715, 0.00339241, 0.00433397, 0.00480828, 0.00767369,\n",
       "        0.00636439, 0.00461025, 0.00400667, 0.00381837, 0.00599322, 0.00656099,\n",
       "        0.0041398 , 0.00637946, 0.00618396, 0.00562372, 0.00575476, 0.00477557,\n",
       "        0.00556078, 0.00520439, 0.00686383, 0.00628133, 0.00677319, 0.00865827,\n",
       "        0.00677218, 0.00876989, 0.00677199, 0.00449767, 0.00603328, 0.00535641,\n",
       "        0.00792041, 0.00907955, 0.00610485, 0.00637727, 0.00700431, 0.00537744,\n",
       "        0.00547442, 0.00649757, 0.00619912, 0.01041174, 0.00929785, 0.00632377,\n",
       "        0.00802345, 0.01546564, 0.01097784, 0.00706892, 0.01011806, 0.01032653,\n",
       "        0.0099277 , 0.00794578, 0.00625582, 0.00592675, 0.00547743, 0.00699229,\n",
       "        0.00624247, 0.00458026, 0.00535679, 0.0055088 , 0.00641694, 0.0060904 ,\n",
       "        0.00564718, 0.00455365, 0.00470057, 0.00667982, 0.00384126, 0.0065414 ,\n",
       "        0.0064651 , 0.00726075, 0.00654283, 0.01097488, 0.00657153, 0.00935087,\n",
       "        0.00957251, 0.01381125, 0.00653582, 0.00714226, 0.00911093, 0.01019988,\n",
       "        0.00844817, 0.00572586, 0.00558734, 0.01086369]),\n",
       " 'std_fit_time': array([3.62172708e-03, 7.08789214e-04, 5.21449429e-04, 7.13429982e-04,\n",
       "        7.01943729e-04, 5.99777552e-04, 6.04437029e-04, 1.46289332e-03,\n",
       "        1.66803097e-03, 1.37724997e-03, 1.79825099e-03, 1.59825899e-03,\n",
       "        2.19959824e-03, 1.17538406e-03, 1.85795766e-03, 1.75682523e-03,\n",
       "        1.50534675e-03, 1.18155223e-03, 2.31436864e-03, 8.36489742e-04,\n",
       "        4.01230631e-05, 1.59702487e-03, 1.35498366e-03, 2.59386614e-03,\n",
       "        2.37949637e-03, 1.04019961e-03, 5.09282877e-04, 3.12345431e-04,\n",
       "        2.50053095e-03, 2.67151830e-03, 1.23172683e-03, 2.21001853e-03,\n",
       "        4.20321601e-03, 1.56653930e-03, 1.99788788e-03, 1.58471739e-03,\n",
       "        1.50924157e-03, 9.47196194e-04, 2.79616640e-03, 3.22996845e-03,\n",
       "        5.83843088e-03, 3.19975668e-03, 2.49628561e-03, 4.20226509e-03,\n",
       "        2.44912738e-03, 1.28717336e-03, 3.53186621e-03, 2.71608868e-03,\n",
       "        2.76462602e-03, 4.55245614e-03, 3.19690347e-03, 3.12469772e-03,\n",
       "        2.25574615e-03, 1.73036518e-03, 9.25124041e-04, 2.92745383e-03,\n",
       "        2.21603615e-03, 2.02000570e-03, 3.26613069e-03, 3.80535815e-03,\n",
       "        3.60482935e-03, 1.39835914e-02, 5.44844833e-03, 3.32024487e-03,\n",
       "        6.37418688e-03, 4.29676625e-03, 3.56543668e-03, 1.65922544e-03,\n",
       "        1.80699416e-03, 3.43962853e-03, 2.30657642e-03, 3.76100984e-03,\n",
       "        3.03601246e-03, 1.70599532e-03, 2.21747415e-03, 2.32878807e-03,\n",
       "        2.32781407e-03, 3.41596875e-03, 1.49127703e-03, 4.90564998e-04,\n",
       "        1.66309315e-03, 3.13434698e-03, 1.09570663e-04, 2.46440052e-03,\n",
       "        2.99978320e-03, 2.36248338e-03, 2.14094711e-03, 1.99286284e-03,\n",
       "        2.00794308e-03, 3.92541875e-03, 2.89347034e-03, 1.09936811e-02,\n",
       "        2.24589839e-03, 1.62076788e-03, 3.48032518e-03, 3.03119437e-03,\n",
       "        2.99361818e-03, 1.48783236e-03, 1.58696195e-03, 3.78327768e-03]),\n",
       " 'mean_score_time': array([0.00354738, 0.00207663, 0.00218096, 0.00215826, 0.00239677, 0.00243583,\n",
       "        0.00229478, 0.00226841, 0.00346594, 0.00268989, 0.00438418, 0.00351229,\n",
       "        0.00278087, 0.00205564, 0.00401273, 0.00391517, 0.00237241, 0.00214081,\n",
       "        0.00208416, 0.00380492, 0.00195966, 0.00267262, 0.00315466, 0.00362759,\n",
       "        0.00362301, 0.00307698, 0.00348034, 0.00220714, 0.00300422, 0.00466456,\n",
       "        0.00237951, 0.00542364, 0.00361481, 0.00320382, 0.00607233, 0.00409713,\n",
       "        0.00345421, 0.00382586, 0.0052052 , 0.00322251, 0.00265121, 0.00600266,\n",
       "        0.00352979, 0.00545216, 0.00229535, 0.00286183, 0.00428095, 0.00205836,\n",
       "        0.00454016, 0.00362716, 0.00293398, 0.00322523, 0.00338864, 0.0037231 ,\n",
       "        0.00488801, 0.00554299, 0.00475874, 0.00671244, 0.00583801, 0.00340228,\n",
       "        0.00308013, 0.00450373, 0.00502644, 0.00419884, 0.00802345, 0.00674205,\n",
       "        0.00703907, 0.00465927, 0.00371294, 0.00311561, 0.00213737, 0.00235171,\n",
       "        0.00395856, 0.00208693, 0.00328922, 0.00271096, 0.00432615, 0.00326834,\n",
       "        0.00250983, 0.00210238, 0.00274568, 0.00293927, 0.00274873, 0.00443492,\n",
       "        0.00351429, 0.00429907, 0.00384583, 0.00413098, 0.00609403, 0.0045711 ,\n",
       "        0.00471325, 0.008673  , 0.00327907, 0.00449238, 0.00558   , 0.00423307,\n",
       "        0.00670457, 0.00340047, 0.00329127, 0.00521669]),\n",
       " 'std_score_time': array([9.94063459e-04, 1.26986042e-04, 3.80391134e-04, 1.42179184e-04,\n",
       "        6.40005416e-04, 5.85528200e-04, 2.77087812e-04, 3.94077095e-04,\n",
       "        1.70641998e-03, 1.12611973e-03, 2.54410892e-03, 1.66916724e-03,\n",
       "        1.47368907e-03, 8.05455453e-05, 2.33485568e-03, 2.97491433e-03,\n",
       "        2.65318622e-04, 2.54887343e-04, 1.00099534e-04, 2.08676085e-03,\n",
       "        9.03218949e-05, 1.48598741e-03, 1.49649402e-03, 1.64240357e-03,\n",
       "        1.77682895e-03, 1.84020150e-03, 1.62500655e-03, 2.15338446e-04,\n",
       "        1.93667388e-03, 1.51505665e-03, 8.88072904e-04, 3.17975780e-03,\n",
       "        1.86677968e-03, 1.15316698e-03, 3.03109833e-03, 2.52431330e-03,\n",
       "        1.86782228e-03, 2.16836777e-03, 2.40770460e-03, 1.54729936e-03,\n",
       "        1.12621535e-03, 2.44045270e-03, 1.27859509e-03, 1.20678792e-03,\n",
       "        2.26225670e-04, 1.36399114e-03, 1.92071728e-03, 1.21188762e-04,\n",
       "        2.07165192e-03, 1.53538063e-03, 1.94327800e-03, 1.75316267e-03,\n",
       "        2.26382071e-03, 2.98256084e-03, 2.20791906e-03, 1.00410045e-03,\n",
       "        1.30124417e-03, 1.52492476e-03, 2.20173908e-03, 1.29305682e-03,\n",
       "        1.57179677e-03, 3.07965616e-03, 3.21797268e-03, 1.48777645e-03,\n",
       "        6.36210532e-03, 3.41193803e-03, 2.88138682e-03, 1.89775079e-03,\n",
       "        1.43958940e-03, 1.98743384e-03, 2.22891938e-04, 5.75307448e-04,\n",
       "        2.46592691e-03, 2.41252149e-04, 1.61527362e-03, 7.32083581e-04,\n",
       "        1.99661718e-03, 1.35340666e-03, 9.26809078e-04, 9.80318519e-05,\n",
       "        1.13349446e-03, 8.26671423e-04, 1.52100679e-03, 2.88153720e-03,\n",
       "        1.23839051e-03, 1.88219570e-03, 1.38864874e-03, 1.20861139e-03,\n",
       "        1.75581529e-03, 2.49659205e-03, 2.40331271e-03, 6.65359216e-03,\n",
       "        1.72412584e-03, 2.16126796e-03, 2.12480581e-03, 2.66220882e-03,\n",
       "        2.26951980e-03, 1.47774785e-03, 2.32677251e-03, 2.58513340e-03]),\n",
       " 'param_preprocessing__polynomial_bedroom__degree': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocessing__polynomial_size__degree': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                    9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7,\n",
       "                    8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6,\n",
       "                    7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5,\n",
       "                    6, 7, 8, 9, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 1,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 2,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 3,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 4,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 5,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 6,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 7,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 8,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 9,\n",
       "   'preprocessing__polynomial_size__degree': 10},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 1},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 2},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 3},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 4},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 5},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 6},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 7},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 8},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 9},\n",
       "  {'preprocessing__polynomial_bedroom__degree': 10,\n",
       "   'preprocessing__polynomial_size__degree': 10}],\n",
       " 'split0_test_score': array([0.53197809, 0.53171602, 0.54522355, 0.54379565, 0.50847886, 0.50803388,\n",
       "        0.50404864, 0.48824759, 0.45353318, 0.40231935, 0.52048972, 0.52917544,\n",
       "        0.53566999, 0.53571259, 0.50847886, 0.50803388, 0.50404864, 0.48824759,\n",
       "        0.45353318, 0.40231935, 0.5242219 , 0.53081818, 0.53590891, 0.5362294 ,\n",
       "        0.50158162, 0.50803388, 0.50404864, 0.48824759, 0.45353318, 0.40231935,\n",
       "        0.53184271, 0.53758574, 0.53945895, 0.53883862, 0.50037316, 0.50803388,\n",
       "        0.50404864, 0.48824759, 0.45353318, 0.40231935, 0.5319609 , 0.53735141,\n",
       "        0.53930072, 0.53887791, 0.50052242, 0.50803388, 0.50404864, 0.48824759,\n",
       "        0.45353318, 0.40231935, 0.53190067, 0.53745662, 0.53938499, 0.53869032,\n",
       "        0.50565347, 0.50164211, 0.50404864, 0.48824759, 0.45353318, 0.40231935,\n",
       "        0.53133617, 0.53727551, 0.54040972, 0.53917886, 0.50525067, 0.50358824,\n",
       "        0.50404864, 0.48824759, 0.45353318, 0.40231935, 0.53065114, 0.53658738,\n",
       "        0.54022423, 0.53965147, 0.50604541, 0.4977158 , 0.50404864, 0.48824759,\n",
       "        0.45353318, 0.40231935, 0.53099301, 0.536678  , 0.54059691, 0.53952784,\n",
       "        0.50739353, 0.49827708, 0.50404864, 0.48824759, 0.45353318, 0.40231918,\n",
       "        0.53012521, 0.53588315, 0.5399751 , 0.54002034, 0.50734457, 0.50007613,\n",
       "        0.50375315, 0.48824759, 0.45353355, 0.40231918]),\n",
       " 'split1_test_score': array([0.53225302, 0.52618888, 0.53488419, 0.53516783, 0.45451042, 0.45231332,\n",
       "        0.44389116, 0.42226201, 0.38464169, 0.33730999, 0.53730671, 0.51997812,\n",
       "        0.53893103, 0.53781855, 0.45451042, 0.45231332, 0.44389116, 0.42226201,\n",
       "        0.38464169, 0.33730999, 0.5354238 , 0.52445722, 0.53895206, 0.53749177,\n",
       "        0.49887582, 0.45231332, 0.44389116, 0.42226201, 0.38464169, 0.33730999,\n",
       "        0.53544608, 0.52151401, 0.53586828, 0.53487707, 0.4983378 , 0.45231332,\n",
       "        0.44389116, 0.42226201, 0.38464169, 0.33730999, 0.53500045, 0.52031442,\n",
       "        0.53451754, 0.53353129, 0.49889726, 0.45231332, 0.44389116, 0.42226201,\n",
       "        0.38464169, 0.33730999, 0.53504   , 0.5213231 , 0.53534431, 0.53373064,\n",
       "        0.49114728, 0.49100047, 0.44389116, 0.42226201, 0.38464169, 0.33730999,\n",
       "        0.53405576, 0.52000604, 0.5331316 , 0.53400577, 0.48943155, 0.48652811,\n",
       "        0.44389116, 0.42226201, 0.38464169, 0.33730999, 0.53534435, 0.52030135,\n",
       "        0.53172174, 0.53048616, 0.49175656, 0.49273121, 0.44389116, 0.42226201,\n",
       "        0.38464169, 0.33730999, 0.53255867, 0.52045329, 0.53188811, 0.53027031,\n",
       "        0.49245972, 0.4899853 , 0.44389113, 0.42226201, 0.38464169, 0.33731018,\n",
       "        0.51743415, 0.50853845, 0.52381461, 0.53062884, 0.49127565, 0.48670151,\n",
       "        0.47003606, 0.42226201, 0.38464169, 0.33731018]),\n",
       " 'split2_test_score': array([ 4.28295335e-01,  4.56095393e-01,  5.12144051e-01,  4.61596230e-01,\n",
       "         1.73388201e-01, -3.94185115e-01, -1.67096399e+00, -4.78706736e+00,\n",
       "        -1.26045513e+01, -3.20376683e+01,  4.34384984e-01,  4.51860030e-01,\n",
       "         5.12220963e-01,  4.70621944e-01,  1.73388200e-01, -3.94185115e-01,\n",
       "        -1.67096399e+00, -4.78706730e+00, -1.26045513e+01, -3.20376683e+01,\n",
       "         4.37847834e-01,  4.43445488e-01,  5.04808139e-01,  4.78667699e-01,\n",
       "         3.49256420e-01, -3.94185115e-01, -1.67096399e+00, -4.78706730e+00,\n",
       "        -1.26045513e+01, -3.20376683e+01,  4.22601291e-01,  4.18640590e-01,\n",
       "         4.72190028e-01,  4.99580538e-01,  3.25875236e-01, -3.94185115e-01,\n",
       "        -1.67096399e+00, -4.78706730e+00, -1.26045513e+01, -3.20376683e+01,\n",
       "         4.19178646e-01,  4.09008772e-01,  4.63061320e-01,  4.99862050e-01,\n",
       "         3.18007628e-01, -3.94185098e-01, -1.67096399e+00, -4.78706730e+00,\n",
       "        -1.26045513e+01, -3.20376683e+01,  4.19085877e-01,  4.09765911e-01,\n",
       "         4.66764739e-01,  4.99052854e-01,  4.36673847e-01,  2.77488562e-01,\n",
       "        -1.67096399e+00, -4.78706730e+00, -1.26045513e+01, -3.20376683e+01,\n",
       "         4.19064840e-01,  4.09793877e-01,  4.72075883e-01,  4.85925311e-01,\n",
       "         4.54114081e-01,  3.12566528e-01, -1.67096399e+00, -4.78706730e+00,\n",
       "        -1.26045513e+01, -3.20376683e+01,  4.19415300e-01,  4.09770612e-01,\n",
       "         4.69446754e-01,  4.79923869e-01,  1.90109695e-01, -3.76863379e-01,\n",
       "        -1.67096389e+00, -4.78706730e+00, -1.26045513e+01, -3.20376683e+01,\n",
       "         4.21259340e-01,  4.11189150e-01,  4.70211810e-01,  4.82802626e-01,\n",
       "        -5.35651830e-02, -5.21516642e-01, -3.13753366e-03, -4.78706730e+00,\n",
       "        -1.26045513e+01, -3.20376514e+01,  4.21475224e-01,  4.11558859e-01,\n",
       "         4.70247122e-01,  4.86811347e-01, -1.43811899e-01, -1.64240307e-01,\n",
       "        -3.58627508e-02, -4.78706731e+00, -1.26045604e+01, -3.20376514e+01]),\n",
       " 'split3_test_score': array([ 5.65747933e-01,  5.82384226e-01,  5.92700784e-01,  5.98211999e-01,\n",
       "         5.47422750e-01,  5.32731294e-01,  3.13703418e-01, -1.49591606e+00,\n",
       "        -1.14656224e+01, -5.01071068e+01,  5.71443248e-01,  5.75605343e-01,\n",
       "         5.95944662e-01,  6.00604937e-01,  5.47422750e-01,  5.32731294e-01,\n",
       "         3.13703418e-01, -1.49591595e+00, -1.14656224e+01, -5.01071068e+01,\n",
       "         5.88074536e-01,  5.83533300e-01,  5.90476921e-01,  5.94607946e-01,\n",
       "         5.78123862e-01,  5.32731294e-01,  3.13703418e-01, -1.49591595e+00,\n",
       "        -1.14656224e+01, -5.01071068e+01,  6.15356800e-01,  6.03073637e-01,\n",
       "         6.00342961e-01,  6.03074113e-01,  5.65100471e-01,  5.32731294e-01,\n",
       "         3.13703418e-01, -1.49591595e+00, -1.14656224e+01, -5.01071068e+01,\n",
       "         6.16704667e-01,  5.89473109e-01,  5.92295885e-01,  6.02401904e-01,\n",
       "         5.50867548e-01,  5.32731294e-01,  3.13703418e-01, -1.49591595e+00,\n",
       "        -1.14656224e+01, -5.01071068e+01,  5.85729787e-01,  6.02705181e-01,\n",
       "         5.80443227e-01,  5.86263815e-01,  5.75908441e-01,  5.80254956e-01,\n",
       "         3.13703418e-01, -1.49591595e+00, -1.14656224e+01, -5.01071068e+01,\n",
       "        -1.68548642e+00, -2.99315879e-01,  9.10996430e-02,  6.02921498e-01,\n",
       "         5.38009476e-01,  5.77098810e-01,  3.13703418e-01, -1.49591595e+00,\n",
       "        -1.14656224e+01, -5.01071068e+01, -7.53704629e+00, -2.94565108e+00,\n",
       "         2.35021598e-03, -7.66536116e-01,  3.89333496e-01,  3.65119026e-01,\n",
       "         3.13703405e-01, -1.49591595e+00, -1.14656224e+01, -5.01071068e+01,\n",
       "        -7.35541490e-01,  3.93171850e-01, -7.37209345e+00, -1.96054718e+00,\n",
       "         5.47489842e-01,  2.46906460e-01,  3.13703471e-01, -1.49591595e+00,\n",
       "        -1.14656224e+01, -5.01068956e+01, -9.23176290e+02, -9.49419000e+02,\n",
       "        -1.98181880e+03, -2.72789891e+00,  7.90393532e-02, -1.14297191e+00,\n",
       "         4.99619841e-01, -1.49591595e+00, -1.14657339e+01, -5.01068956e+01]),\n",
       " 'split4_test_score': array([0.60613781, 0.59097517, 0.60325039, 0.60835332, 0.57550038, 0.5702938 ,\n",
       "        0.55592936, 0.53199328, 0.50402512, 0.46569119, 0.59828957, 0.59121783,\n",
       "        0.60151955, 0.60609193, 0.57550038, 0.5702938 , 0.55592936, 0.53199328,\n",
       "        0.50402512, 0.46569119, 0.59405278, 0.58841648, 0.60004926, 0.60520428,\n",
       "        0.59830952, 0.5702938 , 0.55592936, 0.53199328, 0.50402512, 0.46569119,\n",
       "        0.60239686, 0.59627402, 0.6041018 , 0.60793042, 0.59332897, 0.5702938 ,\n",
       "        0.55592936, 0.53199328, 0.50402512, 0.46569119, 0.60248625, 0.59518882,\n",
       "        0.60357003, 0.60767191, 0.595177  , 0.5702938 , 0.55592936, 0.53199328,\n",
       "        0.50402512, 0.46569119, 0.60255496, 0.59531701, 0.60391651, 0.60742242,\n",
       "        0.60274672, 0.58205813, 0.55592936, 0.53199328, 0.50402512, 0.46569119,\n",
       "        0.60137637, 0.59473349, 0.60528089, 0.60843503, 0.60245949, 0.57970194,\n",
       "        0.55592936, 0.53199328, 0.50402512, 0.46569119, 0.60019991, 0.59380085,\n",
       "        0.60476946, 0.60850058, 0.60202347, 0.58127184, 0.55592936, 0.53199328,\n",
       "        0.50402512, 0.46569119, 0.60150623, 0.59488935, 0.60575142, 0.60843174,\n",
       "        0.60374367, 0.57843237, 0.55592936, 0.53199328, 0.50402512, 0.46569206,\n",
       "        0.60120898, 0.59481444, 0.6048011 , 0.60892435, 0.60362811, 0.59049255,\n",
       "        0.56298264, 0.53199328, 0.50402514, 0.46569206]),\n",
       " 'mean_test_score': array([ 5.32882439e-01,  5.37471938e-01,  5.57640592e-01,  5.49425004e-01,\n",
       "         4.51860122e-01,  3.33837437e-01,  2.93217204e-02, -9.68096108e-01,\n",
       "        -4.54559475e+00, -1.61878909e+01,  5.32382847e-01,  5.33567353e-01,\n",
       "         5.56857238e-01,  5.50169989e-01,  4.51860121e-01,  3.33837437e-01,\n",
       "         2.93217204e-02, -9.68096074e-01, -4.54559475e+00, -1.61878909e+01,\n",
       "         5.35924169e-01,  5.34134134e-01,  5.54039055e-01,  5.50440217e-01,\n",
       "         5.05229447e-01,  3.33837437e-01,  2.93217204e-02, -9.68096074e-01,\n",
       "        -4.54559475e+00, -1.61878909e+01,  5.41528749e-01,  5.35417599e-01,\n",
       "         5.50392405e-01,  5.56860152e-01,  4.96603128e-01,  3.33837437e-01,\n",
       "         2.93217204e-02, -9.68096074e-01, -4.54559475e+00, -1.61878909e+01,\n",
       "         5.41066183e-01,  5.30267305e-01,  5.46549098e-01,  5.56469011e-01,\n",
       "         4.92694372e-01,  3.33837440e-01,  2.93217204e-02, -9.68096074e-01,\n",
       "        -4.54559475e+00, -1.61878909e+01,  5.34862257e-01,  5.33313563e-01,\n",
       "         5.45170756e-01,  5.53032010e-01,  5.22425951e-01,  4.86488846e-01,\n",
       "         2.93217204e-02, -9.68096074e-01, -4.54559475e+00, -1.61878909e+01,\n",
       "         8.00693446e-02,  3.52498608e-01,  4.48399545e-01,  5.54093295e-01,\n",
       "         5.17853052e-01,  4.91896725e-01,  2.93217203e-02, -9.68096074e-01,\n",
       "        -4.54559475e+00, -1.61878909e+01, -1.09028712e+00, -1.77038177e-01,\n",
       "         4.29702480e-01,  2.78405193e-01,  4.35853727e-01,  3.11994900e-01,\n",
       "         2.93217363e-02, -9.68096074e-01, -4.54559475e+00, -1.61878909e+01,\n",
       "         2.70155151e-01,  4.91276328e-01, -1.04472904e+00,  4.00970687e-02,\n",
       "         4.19504316e-01,  2.58416913e-01,  3.62887011e-01, -9.68096074e-01,\n",
       "        -4.54559475e+00, -1.61878451e+01, -1.84221209e+02, -1.89473641e+02,\n",
       "        -3.95935992e+02, -1.12302808e-01,  3.07495156e-01,  5.40115945e-02,\n",
       "         4.00105788e-01, -9.68096076e-01, -4.54561878e+00, -1.61878451e+01]),\n",
       " 'std_test_score': array([5.89680705e-02, 4.82955255e-02, 3.47892014e-02, 5.25386860e-02,\n",
       "        1.45036854e-01, 3.66024084e-01, 8.53978163e-01, 2.05754398e+00,\n",
       "        6.12585890e+00, 2.11063393e+01, 5.59261703e-02, 4.89301804e-02,\n",
       "        3.54547430e-02, 4.97200431e-02, 1.45036855e-01, 3.66024084e-01,\n",
       "        8.53978163e-01, 2.05754395e+00, 6.12585890e+00, 2.11063393e+01,\n",
       "        5.63112009e-02, 5.23754136e-02, 3.58459471e-02, 4.57619818e-02,\n",
       "        8.75885327e-02, 3.66024084e-01, 8.53978163e-01, 2.05754395e+00,\n",
       "        6.12585890e+00, 2.11063393e+01, 6.84544620e-02, 6.65067276e-02,\n",
       "        4.86330335e-02, 4.20306755e-02, 9.29655964e-02, 3.66024084e-01,\n",
       "        8.53978163e-01, 2.05754395e+00, 6.12585890e+00, 2.11063393e+01,\n",
       "        6.99569522e-02, 6.71907829e-02, 5.00233186e-02, 4.18843673e-02,\n",
       "        9.43419526e-02, 3.66024077e-01, 8.53978163e-01, 2.05754395e+00,\n",
       "        6.12585890e+00, 2.11063393e+01, 6.41603923e-02, 6.94040085e-02,\n",
       "        4.68460200e-02, 3.88706740e-02, 5.98746972e-02, 1.11226496e-01,\n",
       "        8.53978163e-01, 2.05754395e+00, 6.12585890e+00, 2.11063393e+01,\n",
       "        8.84715945e-01, 3.31368030e-01, 1.83565213e-01, 4.60652587e-02,\n",
       "        5.01872264e-02, 9.72563457e-02, 8.53978164e-01, 2.05754395e+00,\n",
       "        6.12585890e+00, 2.11063393e+01, 3.22390354e+00, 1.38559003e+00,\n",
       "        2.17936229e-01, 5.24074329e-01, 1.40156087e-01, 3.51287871e-01,\n",
       "        8.53978125e-01, 2.05754395e+00, 6.12585890e+00, 2.11063393e+01,\n",
       "        5.06150914e-01, 7.70541503e-02, 3.16397383e+00, 1.00112645e+00,\n",
       "        2.39652328e-01, 4.05461601e-01, 2.00073290e-01, 2.05754395e+00,\n",
       "        6.12585890e+00, 2.11062690e+01, 3.69477545e+02, 3.79972684e+02,\n",
       "        7.92941405e+02, 1.30838343e+00, 2.88887485e-01, 6.56415927e-01,\n",
       "        2.20060674e-01, 2.05754395e+00, 6.12588653e+00, 2.11062690e+01]),\n",
       " 'rank_test_score': array([ 23,  16,   1,  11,  34,  46,  58,  75,  78,  97,  24,  21,   3,  10,\n",
       "         35,  47,  61,  66,  80,  90,  17,  20,   6,   8,  28,  45,  60,  66,\n",
       "         80,  90,  14,  18,   9,   2,  29,  44,  62,  66,  80,  90,  15,  25,\n",
       "         12,   4,  30,  43,  59,  70,  80,  90,  19,  22,  13,   7,  26,  33,\n",
       "         57,  69,  80,  90,  53,  42,  36,   5,  27,  31,  63,  71,  80,  90,\n",
       "         77,  65,  38,  50,  37,  48,  56,  72,  86,  90,  51,  32,  76,  55,\n",
       "         39,  52,  41,  73,  79,  88,  98,  99, 100,  64,  49,  54,  40,  74,\n",
       "         87,  88], dtype=int32)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gscv_fitted.cv_results_['mean_test_score'])\n",
    "gscv_fitted.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degrees</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.532882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.537472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.557641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.549425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.451860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.054012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0.400106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>-0.968096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>-4.545619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>-16.187845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    degrees     scores\n",
       "0         1   0.532882\n",
       "1         2   0.537472\n",
       "2         3   0.557641\n",
       "3         4   0.549425\n",
       "4         5   0.451860\n",
       "..      ...        ...\n",
       "95       96   0.054012\n",
       "96       97   0.400106\n",
       "97       98  -0.968096\n",
       "98       99  -4.545619\n",
       "99      100 -16.187845\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = {\"degrees\": np.arange(1, 101), \"scores\": gscv_fitted.cv_results_['mean_test_score']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessing__polynomial_bedroom__degree</th>\n",
       "      <th>preprocessing__polynomial_size__degree</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.557641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.556860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.556857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.556469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.554093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-16.187891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-16.187891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-184.221209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-189.473641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>-395.935992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    preprocessing__polynomial_bedroom__degree  ...      scores\n",
       "2                                           1  ...    0.557641\n",
       "33                                          4  ...    0.556860\n",
       "12                                          2  ...    0.556857\n",
       "43                                          5  ...    0.556469\n",
       "63                                          7  ...    0.554093\n",
       "..                                        ...  ...         ...\n",
       "19                                          2  ...  -16.187891\n",
       "9                                           1  ...  -16.187891\n",
       "90                                         10  ... -184.221209\n",
       "91                                         10  ... -189.473641\n",
       "92                                         10  ... -395.935992\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "Q1: The model with bedroom degree = 1 and size degree = 3 had the best R^2 score (which was .5576)\n",
    "\n",
    "Q2: The main downside of trying all those values, is that it could take a while if there are a whole lot of combination. To extreme extent, it can be very expensive time and resources wise to run many models. And we can see that some of the really high degrees are very inefficient models so maybe there is a way to avoid that?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
