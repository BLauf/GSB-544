{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Lab 6 - Variable Selection and Regularization\n",
    "author: Ben Laufer\n",
    "format:\n",
    "    html:\n",
    "        code-fold: true\n",
    "embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "baseball = pd.read_csv('data/Hitters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AtBat         0\n",
      "Hits          0\n",
      "HmRun         0\n",
      "Runs          0\n",
      "RBI           0\n",
      "Walks         0\n",
      "Years         0\n",
      "CAtBat        0\n",
      "CHits         0\n",
      "CHmRun        0\n",
      "CRuns         0\n",
      "CRBI          0\n",
      "CWalks        0\n",
      "League        0\n",
      "Division      0\n",
      "PutOuts       0\n",
      "Assists       0\n",
      "Errors        0\n",
      "Salary       59\n",
      "NewLeague     0\n",
      "dtype: int64\n",
      "AtBat         0\n",
      "Hits          0\n",
      "HmRun         0\n",
      "Runs          0\n",
      "RBI           0\n",
      "Walks         0\n",
      "Years         0\n",
      "CAtBat        0\n",
      "CHits         0\n",
      "CHmRun        0\n",
      "CRuns         0\n",
      "CRBI          0\n",
      "CWalks        0\n",
      "League        0\n",
      "Division      0\n",
      "PutOuts       0\n",
      "Assists       0\n",
      "Errors        0\n",
      "Salary       59\n",
      "NewLeague     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Although it isn’t listed as a specific question, don’t forget to clean your data at the beginning. \n",
    "#How will you handle missing data?\n",
    "#Are there any variables that need adjusting?\n",
    "\n",
    "#clean data\n",
    "#find number of NA's per column\n",
    "na_counts = baseball.isna().sum()\n",
    "print(na_counts)\n",
    "\n",
    "#only NA's are salary\n",
    "#for now will choose to remove the observations where salary is NA\n",
    "baseball = baseball.dropna()\n",
    "\n",
    "\n",
    "#another thing we could do, but does not seem to important for this model is that we save the values that dont have a corresponding and we use it as a test dataset for our model.\n",
    "#that way we our using our model on new data and not data that it was already built on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part I: Different Model Specs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Regression without regularization**\n",
    "\n",
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary linear regression\n",
    "\n",
    "2. Fit this pipeline to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "3. Use cross-validation to estimate the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary linear regression\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_linear = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>League_A</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_E</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_A</th>\n",
       "      <th>NewLeague_N</th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   League_A  League_N  Division_E  Division_W  NewLeague_A  NewLeague_N  ...  CRuns  CRBI  CWalks  PutOuts  Assists  Errors\n",
       "1       NaN       NaN         NaN         NaN          NaN          NaN  ...    NaN   NaN     NaN      NaN      NaN     NaN\n",
       "2       NaN       NaN         NaN         NaN          NaN          NaN  ...    NaN   NaN     NaN      NaN      NaN     NaN\n",
       "3       NaN       NaN         NaN         NaN          NaN          NaN  ...    NaN   NaN     NaN      NaN      NaN     NaN\n",
       "4       NaN       NaN         NaN         NaN          NaN          NaN  ...    NaN   NaN     NaN      NaN      NaN     NaN\n",
       "5       NaN       NaN         NaN         NaN          NaN          NaN  ...    NaN   NaN     NaN      NaN      NaN     NaN\n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the data\n",
    "X_1 = ct.fit_transform(X)\n",
    "\n",
    "# Retrieve feature names\n",
    "#REFRENCED CHAT GPT TO GET COLUMN NAMES TO MAKE SURE ALL COLS WERE SELECTED\n",
    "ohe_feature_names = ct.named_transformers_['dummify'].get_feature_names_out(X.select_dtypes(include='object').columns)\n",
    "num_feature_names = X.select_dtypes(include=np.number).columns\n",
    "all_feature_names = np.concatenate([ohe_feature_names, num_feature_names])\n",
    "\n",
    "# Create a DataFrame with the transformed data\n",
    "X_1_df = pd.DataFrame(X_1, columns=all_feature_names)\n",
    "#X_1_df.head()\n",
    "\n",
    "#all columns are there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>League_A</td>\n",
       "      <td>-31.299712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>League_N</td>\n",
       "      <td>31.299712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Division_E</td>\n",
       "      <td>58.424623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Division_W</td>\n",
       "      <td>-58.424623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewLeague_A</td>\n",
       "      <td>12.381163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NewLeague_N</td>\n",
       "      <td>-12.381163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>-291.094556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits</td>\n",
       "      <td>337.830479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>37.853837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Runs</td>\n",
       "      <td>-60.572479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RBI</td>\n",
       "      <td>-26.994984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walks</td>\n",
       "      <td>135.073897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years</td>\n",
       "      <td>-16.693359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>-391.038655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHits</td>\n",
       "      <td>86.687617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHmRun</td>\n",
       "      <td>-14.181723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>480.747135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>260.689886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>-213.892259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>78.761296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Assists</td>\n",
       "      <td>53.732490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Errors</td>\n",
       "      <td>-22.160862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Coefficient\n",
       "0      League_A   -31.299712\n",
       "1      League_N    31.299712\n",
       "2    Division_E    58.424623\n",
       "3    Division_W   -58.424623\n",
       "4   NewLeague_A    12.381163\n",
       "5   NewLeague_N   -12.381163\n",
       "6         AtBat  -291.094556\n",
       "7          Hits   337.830479\n",
       "8         HmRun    37.853837\n",
       "9          Runs   -60.572479\n",
       "10          RBI   -26.994984\n",
       "11        Walks   135.073897\n",
       "12        Years   -16.693359\n",
       "13       CAtBat  -391.038655\n",
       "14        CHits    86.687617\n",
       "15       CHmRun   -14.181723\n",
       "16        CRuns   480.747135\n",
       "17         CRBI   260.689886\n",
       "18       CWalks  -213.892259\n",
       "19      PutOuts    78.761296\n",
       "20      Assists    53.732490\n",
       "21       Errors   -22.160862"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline to the full dataset\n",
    "lr_pipeline_linear.fit(X, y)\n",
    "\n",
    "# Get feature names from the ColumnTransformer\n",
    "#REFRENCED CHAT GPT TO GET COLUMN NAMES TO MAKE SURE ALL COLS WERE SELECTED\n",
    "ohe_feature_names = ct.named_transformers_['dummify'].get_feature_names_out(X.select_dtypes(include='object').columns)\n",
    "num_feature_names = X.select_dtypes(include=np.number).columns\n",
    "all_feature_names = np.concatenate([ohe_feature_names, num_feature_names])\n",
    "\n",
    "# Get coefficients from the linear regression model\n",
    "coefficients = lr_pipeline_linear.named_steps[\"linear_regression\"].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and their corresponding coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    \"Feature\": all_feature_names,\n",
    "    \"Coefficient\": coefficients\n",
    "})\n",
    "\n",
    "# Display the top coefficients\n",
    "coeff_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most important coefficients in this case, we see that we have all the categorical options for all the dummy variables we converted. So in order to accurately estimate that we would find the total amount between the two groups.\n",
    "\n",
    "For instance for league_N and league_A: A player's salary is estimated to make 31.299712+31.299712=62.599424 thousand MORE if they play in the A league versus the N league. This would work the same for the NewLeague dummy variable as well as the Division dummy variable.\n",
    "\n",
    "The highest coefficients we see in our models are CRuns: 480, Hits: 337 and CAtBat: -391\n",
    "\n",
    "CRuns: For every 1 standard deviation increase in number of home runs during a player's career, there is an estimated 480 (thousand) increase in that players salary\n",
    "\n",
    "Hits: For every 1 standard deviation increase in the player's number of hits in 1986, there is an estimated 337 (thousand) increase in that players salary\n",
    "\n",
    "CAtBat: For every 1 standard deviation increase in the player's number of times at bar during their career, there is an estimated -391 (thousand) DECREASE in that players salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.3456645862518122  mse:  120656.57125044877\n",
      "r2:  0.3456645862518122  mse:  120656.57125044877\n"
     ]
    }
   ],
   "source": [
    "#Use cross-validation to estimate the MSE you would expect if you used this pipeline to predict 1989 salaries.\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Ridge regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression\n",
    "\n",
    "2. Use cross-validation to tune the lambda hyperparameter.\n",
    "\n",
    "3. Fit the pipeline with your chosen to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "4. Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"ridge_regression\", Ridge(alpha = 1))]\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ridge_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.385012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.368328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.355767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.347675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.344084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.343556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ridge_regression__alpha    scores\n",
       "5                  100.000  0.385012\n",
       "4                   10.000  0.368328\n",
       "3                    1.000  0.355767\n",
       "2                    0.100  0.347675\n",
       "1                    0.010  0.344084\n",
       "0                    0.001  0.343556"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use cross-validation to tune the hyperparameter.\n",
    "\n",
    "#tune lambdas to test multiple vals\n",
    "lambdas = {\"ridge_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_1, lambdas, cv = 5, scoring='r2')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the pipeline with your chosen to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_ridge = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  #changed alpha = 100\n",
    "  (\"ridge_regression\", Ridge(alpha = 100))]\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>League_A</td>\n",
       "      <td>-11.051842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>League_N</td>\n",
       "      <td>11.051842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Division_E</td>\n",
       "      <td>38.023222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Division_W</td>\n",
       "      <td>-38.023222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewLeague_A</td>\n",
       "      <td>-4.091590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NewLeague_N</td>\n",
       "      <td>4.091590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>-0.567370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits</td>\n",
       "      <td>49.612386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>-1.464159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Runs</td>\n",
       "      <td>29.343263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RBI</td>\n",
       "      <td>22.958015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walks</td>\n",
       "      <td>41.384617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years</td>\n",
       "      <td>-2.708306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>24.705844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHits</td>\n",
       "      <td>44.534276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHmRun</td>\n",
       "      <td>38.685330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>45.507606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>47.145556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>4.036371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>56.881522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Assists</td>\n",
       "      <td>7.457239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Errors</td>\n",
       "      <td>-13.382390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Coefficient\n",
       "0      League_A   -11.051842\n",
       "1      League_N    11.051842\n",
       "2    Division_E    38.023222\n",
       "3    Division_W   -38.023222\n",
       "4   NewLeague_A    -4.091590\n",
       "5   NewLeague_N     4.091590\n",
       "6         AtBat    -0.567370\n",
       "7          Hits    49.612386\n",
       "8         HmRun    -1.464159\n",
       "9          Runs    29.343263\n",
       "10          RBI    22.958015\n",
       "11        Walks    41.384617\n",
       "12        Years    -2.708306\n",
       "13       CAtBat    24.705844\n",
       "14        CHits    44.534276\n",
       "15       CHmRun    38.685330\n",
       "16        CRuns    45.507606\n",
       "17         CRBI    47.145556\n",
       "18       CWalks     4.036371\n",
       "19      PutOuts    56.881522\n",
       "20      Assists     7.457239\n",
       "21       Errors   -13.382390"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output all variables coeff.\n",
    "# Fit the pipeline to the full dataset\n",
    "lr_pipeline_ridge.fit(X, y)\n",
    "\n",
    "# Get feature names from the ColumnTransformer\n",
    "#REFRENCED CHAT GPT TO GET COLUMN NAMES TO MAKE SURE ALL COLS WERE SELECTED\n",
    "ohe_feature_names = ct.named_transformers_['dummify'].get_feature_names_out(X.select_dtypes(include='object').columns)\n",
    "num_feature_names = X.select_dtypes(include=np.number).columns\n",
    "all_feature_names = np.concatenate([ohe_feature_names, num_feature_names])\n",
    "\n",
    "# Get coefficients from the linear regression model\n",
    "coefficients = lr_pipeline_ridge.named_steps[\"ridge_regression\"].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and their corresponding coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    \"Feature\": all_feature_names,\n",
    "    \"Coefficient\": coefficients\n",
    "})\n",
    "\n",
    "# Display the top coefficients\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main changes we see are that a lot of the very large coefficients of variables have changed (specifically CRuns, Hits, and CAtBat). Additionally, the coefficient for CAtBat is now positive!\n",
    "\n",
    "CRuns: For every 1 standard deviation increase in number of home runs during a player's career, there is an estimated 44.53 (thousand) increase in that players salary\n",
    "\n",
    "Hits: For every 1 standard deviation increase in the player's number of hits in 1986, there is an estimated 49.61 (thousand) increase in that players salary\n",
    "\n",
    "CAtBat: For every 1 standard deviation increase in the player's number of times at bar during their career, there is an estimated 24.70 (thousand) INCREASE in that players salary)\n",
    "\n",
    "Overall most of the coefficients of our predictors are lower.\n",
    "\n",
    "Some of the other most important coefficients now include PutOuts and CRBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.3850122123151716  mse:  120716.43558937623\n",
      "r2:  0.3850122123151716  mse:  120716.43558937623\n"
     ]
    }
   ],
   "source": [
    "#Report the MSE you would expect if you used this pipeline to predict 1989 salaries.\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_ridge, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_ridge, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Lasso Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression\n",
    "\n",
    "2. Use cross-validation to tune the alpha hyperparameter.\n",
    "\n",
    "3. Fit the pipeline with your chosen to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "4. Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary lasso regression\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"lasso_regression\", Lasso(alpha = 1))]\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.984e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.096e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.537e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.594e+06, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.059e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.591e+06, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.471e+05, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.066e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.923e+04, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+05, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+05, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.929e+04, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.282e+05, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.815e+03, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.369523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.354238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.346041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.344394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.344223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.298382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lasso_regression__alpha    scores\n",
       "4                   10.000  0.369523\n",
       "3                    1.000  0.354238\n",
       "2                    0.100  0.346041\n",
       "1                    0.010  0.344394\n",
       "0                    0.001  0.344223\n",
       "5                  100.000  0.298382"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use cross-validation to tune the hyperparameter.\n",
    "\n",
    "#tune lambdas to test multiple vals\n",
    "lambdas = {\"lasso_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_1, lambdas, cv = 5, scoring='r2')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the pipeline with your chosen to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_lasso = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  #changed alpha = 10\n",
    "  (\"lasso_regression\", Lasso(alpha = 10))]\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>League_A</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>League_N</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Division_E</td>\n",
       "      <td>9.541320e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Division_W</td>\n",
       "      <td>-3.327948e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewLeague_A</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NewLeague_N</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits</td>\n",
       "      <td>8.874163e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Runs</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RBI</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walks</td>\n",
       "      <td>4.990281e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHits</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHmRun</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>7.222753e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>1.340320e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>6.673701e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Assists</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Errors</td>\n",
       "      <td>-4.158281e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature   Coefficient\n",
       "0      League_A -0.000000e+00\n",
       "1      League_N  0.000000e+00\n",
       "2    Division_E  9.541320e+01\n",
       "3    Division_W -3.327948e-12\n",
       "4   NewLeague_A -0.000000e+00\n",
       "5   NewLeague_N  0.000000e+00\n",
       "6         AtBat -0.000000e+00\n",
       "7          Hits  8.874163e+01\n",
       "8         HmRun  0.000000e+00\n",
       "9          Runs  0.000000e+00\n",
       "10          RBI  0.000000e+00\n",
       "11        Walks  4.990281e+01\n",
       "12        Years -0.000000e+00\n",
       "13       CAtBat  0.000000e+00\n",
       "14        CHits  0.000000e+00\n",
       "15       CHmRun  0.000000e+00\n",
       "16        CRuns  7.222753e+01\n",
       "17         CRBI  1.340320e+02\n",
       "18       CWalks -0.000000e+00\n",
       "19      PutOuts  6.673701e+01\n",
       "20      Assists  0.000000e+00\n",
       "21       Errors -4.158281e+00"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output all variables coeff.\n",
    "# Fit the pipeline to the full dataset\n",
    "lr_pipeline_lasso.fit(X, y)\n",
    "\n",
    "# Get feature names from the ColumnTransformer\n",
    "#REFRENCED CHAT GPT TO GET COLUMN NAMES TO MAKE SURE ALL COLS WERE SELECTED\n",
    "ohe_feature_names = ct.named_transformers_['dummify'].get_feature_names_out(X.select_dtypes(include='object').columns)\n",
    "num_feature_names = X.select_dtypes(include=np.number).columns\n",
    "all_feature_names = np.concatenate([ohe_feature_names, num_feature_names])\n",
    "\n",
    "# Get coefficients from the linear regression model\n",
    "coefficients = lr_pipeline_lasso.named_steps[\"lasso_regression\"].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and their corresponding coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    \"Feature\": all_feature_names,\n",
    "    \"Coefficient\": coefficients\n",
    "})\n",
    "\n",
    "# Display the top coefficients\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our hyperparameter (alpha = 10). Above are the coefficients from the optimized lasso model using every variable.\n",
    "\n",
    "Some of the most important changes we see in our coefficients is that many of the ones that the lasso model deemed as redundant or unimportant are now zero'd out. These variables include but are not limited to League, Runs, and Years.\n",
    "\n",
    "The variables the method chose to be the most \"important\" include Division, Hits, Walks, CRuns, CRBI, PutOuts, and Errors.\n",
    "\n",
    "Hits: For every 1 standard deviation increase in the player's number of hits in 1986, there is an estimated 8.874163e+01 (thousand) increase in that players salary\n",
    "\n",
    "Walks: For every 1 standard deviation increase in the player's number of walks in 1986, there is an estimated 4.990281e+01(thousand) increase in that players salary\n",
    "\n",
    "PutOuts: For every 1 standard deviation increase in the player's number of put outs in 1986, there is an estimated 6.673701e+01(thousand) increase in that players salary\n",
    "\n",
    "(can interpret like this too it should work, although its not the same way I did for the ordinary regression output)\n",
    "Division_W: If a player division at the end of 1986 was level W, there is an estimated -3.327948e-12 (thousand) DECREASE in that players salary\n",
    "\n",
    "Division_E: If a player division at the end of 1986 was level E, there is an estimated 9.541320e+01 (thousand) increase in that players salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.3695225743376409  mse:  121828.14133338635\n",
      "r2:  0.3695225743376409  mse:  121828.14133338635\n"
     ]
    }
   ],
   "source": [
    "#Report the MSE you would expect if you used this pipeline to predict 1989 salaries.\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_lasso, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_lasso, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D. Elastic Net**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary elastic net regression\n",
    "\n",
    "2. Use cross-validation to tune the lambda and alpha hyperparameters.\n",
    "\n",
    "3. Fit the pipeline with your chosen hyperparameters to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "4. Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary elastic net regression\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"elastic_regression\", ElasticNet(alpha = .01, l1_ratio = .5))]\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.137e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.359e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.710e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.075e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.278e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.657e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.035e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.206e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.621e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.010e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.136e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.596e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.995e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.060e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.579e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.986e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.963e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.566e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.816e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.557e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.981e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.525e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.550e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.488e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.543e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.601e+03, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+05, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+04, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.270e+05, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.610e+04, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+04, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.133e+05, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.634e+04, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.792e+05, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.632e+04, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.947e+04, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.597e+05, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.940e+05, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.672e+06, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.925e+05, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.683e+05, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elastic_regression__alpha</th>\n",
       "      <th>elastic_regression__l1_ratio</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.386643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.386557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.386511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.386203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.385538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elastic_regression__alpha  elastic_regression__l1_ratio    scores\n",
       "28                        1.0                           0.2  0.386643\n",
       "29                        1.0                           0.3  0.386557\n",
       "27                        1.0                           0.1  0.386511\n",
       "30                        1.0                           0.4  0.386203\n",
       "31                        1.0                           0.5  0.385538"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use cross-validation to tune the lambda and alpha hyperparameters.\n",
    "\n",
    "#Use cross-validation to tune the hyperparameter.\n",
    "\n",
    "#tune lambdas/alphas to test multiple vals\n",
    "values = {\"elastic_regression__alpha\": [.001, .01, .1, 1, 10, 100],\n",
    "          \"elastic_regression__l1_ratio\": [.1, .2, .3, .4, .5, .6, .7, .8, .9]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_1, values, cv = 5, scoring='r2')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the pipeline with your chosen hyperparameters to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_elastic = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  #can now put our custom alpha and l1_ratio that we found in the previous step\n",
    "  (\"elastic_regression\", ElasticNet(alpha = 1, l1_ratio = .2))]\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>League_A</td>\n",
       "      <td>-7.248569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>League_N</td>\n",
       "      <td>7.248595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Division_E</td>\n",
       "      <td>26.103984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Division_W</td>\n",
       "      <td>-26.103971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewLeague_A</td>\n",
       "      <td>-4.116523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NewLeague_N</td>\n",
       "      <td>4.116546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>12.179419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits</td>\n",
       "      <td>37.450668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>5.609999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Runs</td>\n",
       "      <td>27.011028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RBI</td>\n",
       "      <td>22.983192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walks</td>\n",
       "      <td>34.568563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years</td>\n",
       "      <td>7.634212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>25.867403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHits</td>\n",
       "      <td>36.124822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHmRun</td>\n",
       "      <td>32.312440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>36.943114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>37.880465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>15.355773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>44.835142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Assists</td>\n",
       "      <td>3.836558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Errors</td>\n",
       "      <td>-8.036185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Coefficient\n",
       "0      League_A    -7.248569\n",
       "1      League_N     7.248595\n",
       "2    Division_E    26.103984\n",
       "3    Division_W   -26.103971\n",
       "4   NewLeague_A    -4.116523\n",
       "5   NewLeague_N     4.116546\n",
       "6         AtBat    12.179419\n",
       "7          Hits    37.450668\n",
       "8         HmRun     5.609999\n",
       "9          Runs    27.011028\n",
       "10          RBI    22.983192\n",
       "11        Walks    34.568563\n",
       "12        Years     7.634212\n",
       "13       CAtBat    25.867403\n",
       "14        CHits    36.124822\n",
       "15       CHmRun    32.312440\n",
       "16        CRuns    36.943114\n",
       "17         CRBI    37.880465\n",
       "18       CWalks    15.355773\n",
       "19      PutOuts    44.835142\n",
       "20      Assists     3.836558\n",
       "21       Errors    -8.036185"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output all variables coeff.\n",
    "# Fit the pipeline to the full dataset\n",
    "lr_pipeline_elastic.fit(X, y)\n",
    "\n",
    "# Get feature names from the ColumnTransformer\n",
    "#REFRENCED CHAT GPT TO GET COLUMN NAMES TO MAKE SURE ALL COLS WERE SELECTED\n",
    "ohe_feature_names = ct.named_transformers_['dummify'].get_feature_names_out(X.select_dtypes(include='object').columns)\n",
    "num_feature_names = X.select_dtypes(include=np.number).columns\n",
    "all_feature_names = np.concatenate([ohe_feature_names, num_feature_names])\n",
    "\n",
    "# Get coefficients from the linear regression model\n",
    "coefficients = lr_pipeline_elastic.named_steps[\"elastic_regression\"].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and their corresponding coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    \"Feature\": all_feature_names,\n",
    "    \"Coefficient\": coefficients\n",
    "})\n",
    "\n",
    "# Display the top coefficients\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elastic regression with parameters lambda = 1 and l1_ratio = .2 definitely has similiar coefficients to the previous steps (that is because the elastic regression uses a combination of two calculations to find its own penalty formula) Where that ratio of which type is more effective is determined by the l1_ratio.\n",
    "\n",
    "Because 0 would mean a pure ridge regression and 1 would mean a pure lasso regression\n",
    "\n",
    "that means that essentially 80% of the penalty weight is on a ridge penalty and 20% is on a lasso penalty. As a result we can see that are values are a lot more similiar to the ridge regression, (even though we used a completely different alpha value)\n",
    "\n",
    "**Some of the most notable coefficient changes from the previous regression (lasso) are that many of the variables that were not zero'd out are here and very large (this is most likely because the variables have a lot of multicollinearity between them such as CHits and Hits being extremely correlated). We see that almost every variable has been significantly changed and that there are unlike the previous model, PutOuts is now the variable with the highest coefficient (when before it was Hits)\n",
    "\n",
    "Interpretation of Walks output: For every 1 standard deviation increase in a players number of walks in 1986, their salary is expected to increase by 34.56 (thousand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.3866433466516488  mse:  121500.81646251371\n",
      "r2:  0.3866433466516488  mse:  121500.81646251371\n"
     ]
    }
   ],
   "source": [
    "#Report the MSE you would expect if you used this pipeline to predict 1989 salaries.\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_elastic, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_elastic, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)\n",
    "\n",
    "#this combination has given us the highest R^2 and lowest MSE compared to all the previous regression with their corresponding hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part II. Variable Selection**\n",
    "\n",
    "Based on the above results, decide on:\n",
    "\n",
    "- Which numeric variable is most important.\n",
    "\n",
    "- Which five numeric variables are most important\n",
    "\n",
    "- Which categorical variable is most important\n",
    "\n",
    "For each of the four model specifications, compare the following possible feature sets:\n",
    "\n",
    "1. Using only the one best numeric variable.\n",
    "\n",
    "2. Using only the five best variables.\n",
    "\n",
    "3. Using the five best numeric variables and their interactions with the one best categorical variable.\n",
    "\n",
    "Report which combination of features and model performed best, based on the validation metric of MSE.\n",
    "\n",
    "(Note: \n",
    " and \n",
    " must be re-tuned for each feature set.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable Selection**\n",
    "\n",
    "1. Most Important Numeric Variable: CRuns\n",
    "\n",
    "2. Top 5 Most Important Numeric Variables: CRuns, PutOuts, Hits, CRBI, Walks\n",
    "\n",
    "3. Most Important Categorical Variable: Division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Regression without regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.29227548589102115  mse:  143812.9359162973\n",
      "r2:  0.29227548589102115  mse:  143812.9359162973\n"
     ]
    }
   ],
   "source": [
    "#Using only the one best numeric variable.\n",
    "X = baseball[[\"CRuns\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.37722674799137945  mse:  121332.85377811702\n",
      "r2:  0.37722674799137945  mse:  121332.85377811702\n"
     ]
    }
   ],
   "source": [
    "#Using only the five best variables.\n",
    "X = baseball[[\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the five best numeric variables and their interactions with the one best categorical variable.\n",
    "\n",
    "X = baseball[[\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\", \"Division\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    #drop = \"first\" should make it so that division is not included in the model\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False, drop = \"first\"), [\"Division\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "#interaction terms\n",
    "ct_inter = ColumnTransformer(\n",
    "  [\n",
    "    #i think this part makes it so that division by itself is not included in the model\n",
    "    (\"interaction_CRuns_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRuns\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_PutOuts_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__PutOuts\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Hits_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Hits\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_CRBI_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRBI\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Walks_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Walks\", \"dummify__Division_W\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ").set_output(transform = \"pandas\")\n",
    "\n",
    "\n",
    "lr_pipeline_linear = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "   (\"interaction\", ct_inter),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.320279729122522  mse:  130401.97016858231\n",
      "r2:  0.320279729122522  mse:  130401.97016858231\n"
     ]
    }
   ],
   "source": [
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Ridge regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ridge_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>143658.517369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>143783.706854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>143809.862456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>143812.627051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>143812.905015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>148807.783475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ridge_regression__alpha         scores\n",
       "4                   10.000  143658.517369\n",
       "3                    1.000  143783.706854\n",
       "2                    0.100  143809.862456\n",
       "1                    0.010  143812.627051\n",
       "0                    0.001  143812.905015\n",
       "5                  100.000  148807.783475"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retune hyperparameter and score how well the model did (in MSE)\n",
    "\n",
    "#Using only the one best numeric variable.\n",
    "X = baseball[[\"CRuns\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#tune lambdas to test multiple vals\n",
    "lambdas = {\"ridge_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_ridge, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df['scores'] = results_df['scores']*-1\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ridge_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>119398.400113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>119969.294948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>121103.353500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>121307.910944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>121330.337137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>121332.601888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ridge_regression__alpha         scores\n",
       "5                  100.000  119398.400113\n",
       "4                   10.000  119969.294948\n",
       "3                    1.000  121103.353500\n",
       "2                    0.100  121307.910944\n",
       "1                    0.010  121330.337137\n",
       "0                    0.001  121332.601888"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retune hyperparameter and score how well the model did (in MSE)\n",
    "\n",
    "#Using only the five best variables.\n",
    "X = baseball[[\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#tune lambdas to test multiple vals\n",
    "lambdas = {\"ridge_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_ridge, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df['scores'] = results_df['scores']*-1\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    #drop = \"first\" should make it so that division is not included in the model\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False, drop = \"first\"), [\"Division\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "#interaction terms\n",
    "ct_inter = ColumnTransformer(\n",
    "  [\n",
    "    #i think this part makes it so that division by itself is not included in the model\n",
    "    (\"interaction_CRuns_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRuns\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_PutOuts_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__PutOuts\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Hits_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Hits\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_CRBI_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRBI\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Walks_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Walks\", \"dummify__Division_W\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ").set_output(transform = \"pandas\")\n",
    "\n",
    "\n",
    "lr_pipeline_ridge = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "   (\"interaction\", ct_inter),\n",
    "   (\"ridge_regression\", Ridge(alpha = 100))]\n",
    ").set_output(transform=\"pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ridge_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.00</td>\n",
       "      <td>116972.675912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.00</td>\n",
       "      <td>118503.794116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>125192.212120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>129543.747309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>130310.159254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ridge_regression__alpha         scores\n",
       "5                   100.00  116972.675912\n",
       "4                    10.00  118503.794116\n",
       "3                     1.00  125192.212120\n",
       "2                     0.10  129543.747309\n",
       "1                     0.01  130310.159254"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retune hyperparameter\n",
    "\n",
    "#Using the five best numeric variables and their interactions with the one best categorical variable.\n",
    "\n",
    "X = baseball[[\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\", \"Division\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#tune lambdas to test multiple vals\n",
    "lambdas = {\"ridge_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_ridge, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df['scores'] = results_df['scores'] * -1\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Lasso Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>143793.449159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>143801.606084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>143811.709122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>143812.812299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>143812.923545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>152999.224797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lasso_regression__alpha         scores\n",
       "4                   10.000  143793.449159\n",
       "3                    1.000  143801.606084\n",
       "2                    0.100  143811.709122\n",
       "1                    0.010  143812.812299\n",
       "0                    0.001  143812.923545\n",
       "5                  100.000  152999.224797"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retune hyperparameter and score how well the model did (in MSE)\n",
    "\n",
    "#Using only the one best numeric variable.\n",
    "X = baseball[[\"CRuns\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#tune lambdas to test multiple vals\n",
    "lambdas = {\"lasso_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_lasso, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df['scores'] = results_df['scores']*-1\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>121332.402601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>121332.659779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>121332.893433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>121337.557109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>121600.010609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>142592.153396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lasso_regression__alpha         scores\n",
       "1                    0.010  121332.402601\n",
       "2                    0.100  121332.659779\n",
       "0                    0.001  121332.893433\n",
       "3                    1.000  121337.557109\n",
       "4                   10.000  121600.010609\n",
       "5                  100.000  142592.153396"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retune hyperparameter and score how well the model did (in MSE)\n",
    "\n",
    "#Using only the five best variables.\n",
    "X = baseball[[\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#tune lambdas to test multiple vals\n",
    "lambdas = {\"lasso_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_lasso, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df['scores'] = results_df['scores']*-1\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    #drop = \"first\" should make it so that division is not included in the model\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False, drop = \"first\"), [\"Division\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "#interaction terms\n",
    "ct_inter = ColumnTransformer(\n",
    "  [\n",
    "    #i think this part makes it so that division by itself is not included in the model\n",
    "    (\"interaction_CRuns_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRuns\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_PutOuts_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__PutOuts\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Hits_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Hits\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_CRBI_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRBI\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Walks_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Walks\", \"dummify__Division_W\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ").set_output(transform = \"pandas\")\n",
    "\n",
    "\n",
    "lr_pipeline_lasso = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "   (\"interaction\", ct_inter),\n",
    "  (\"lasso_regression\", Lasso(alpha = 10))]\n",
    ").set_output(transform=\"pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+05, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+04, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.136e+05, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.770e+04, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>119129.330501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>126202.590816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>129953.501522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>130358.354217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>130397.415306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>142592.153396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lasso_regression__alpha         scores\n",
       "4                   10.000  119129.330501\n",
       "3                    1.000  126202.590816\n",
       "2                    0.100  129953.501522\n",
       "1                    0.010  130358.354217\n",
       "0                    0.001  130397.415306\n",
       "5                  100.000  142592.153396"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retune hyperparameter and score how well the model did (in MSE)\n",
    "\n",
    "#Using the five best numeric variables and their interactions with the one best categorical variable.\n",
    "X = baseball[[\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\", \"Division\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#tune lambdas to test multiple vals\n",
    "lambdas = {\"lasso_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_lasso, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df['scores'] = results_df['scores']*-1\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D. Elastic Net**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elastic_regression__alpha</th>\n",
       "      <th>elastic_regression__l1_ratio</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>143655.076048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>143660.021761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>143661.305279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>143675.521978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>143679.366378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elastic_regression__alpha  elastic_regression__l1_ratio         scores\n",
       "22                        0.1                           0.5  143655.076048\n",
       "21                        0.1                           0.4  143660.021761\n",
       "23                        0.1                           0.6  143661.305279\n",
       "20                        0.1                           0.3  143675.521978\n",
       "24                        0.1                           0.7  143679.366378"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using only the one best numeric variable.\n",
    "X = baseball[[\"CRuns\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#Use cross-validation to tune the lambda and alpha hyperparameters.\n",
    "\n",
    "#tune lambdas/alphas to test multiple vals\n",
    "values = {\"elastic_regression__alpha\": [.001, .01, .1, 1, 10, 100],\n",
    "          \"elastic_regression__l1_ratio\": [.1, .2, .3, .4, .5, .6, .7, .8, .9]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_elastic, values, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df['scores'] = results_df['scores']*-1\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elastic_regression__alpha</th>\n",
       "      <th>elastic_regression__l1_ratio</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>118839.350432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>118860.691338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>119107.904838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>119352.498787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>119416.439601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elastic_regression__alpha  elastic_regression__l1_ratio         scores\n",
       "33                        1.0                           0.7  118839.350432\n",
       "34                        1.0                           0.8  118860.691338\n",
       "32                        1.0                           0.6  119107.904838\n",
       "35                        1.0                           0.9  119352.498787\n",
       "18                        0.1                           0.1  119416.439601"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using only the five best variables.\n",
    "X = baseball[[\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#tune lambdas/alphas to test multiple vals\n",
    "values = {\"elastic_regression__alpha\": [.001, .01, .1, 1, 10, 100],\n",
    "          \"elastic_regression__l1_ratio\": [.1, .2, .3, .4, .5, .6, .7, .8, .9]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_elastic, values, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df['scores'] = results_df['scores']*-1\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    #drop = \"first\" should make it so that division is not included in the model\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False, drop = \"first\"), [\"Division\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "#interaction terms\n",
    "ct_inter = ColumnTransformer(\n",
    "  [\n",
    "    #i think this part makes it so that division by itself is not included in the model\n",
    "    (\"interaction_CRuns_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRuns\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_PutOuts_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__PutOuts\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Hits_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Hits\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_CRBI_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRBI\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Walks_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Walks\", \"dummify__Division_W\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ").set_output(transform = \"pandas\")\n",
    "\n",
    "#elastic pipeline\n",
    "lr_pipeline_elastic = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "   (\"interaction\", ct_inter),\n",
    "  (\"elastic_regression\", ElasticNet(alpha = 1, l1_ratio = .8))]\n",
    ").set_output(transform=\"pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.991e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.952e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+07, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.735e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.902e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+07, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.754e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.874e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+07, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.757e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.830e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+07, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.096e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.681e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.807e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+07, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.624e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.762e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+07, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.554e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+07, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.638e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+07, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.252e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.736e+06, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.537e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.928e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.854e+06, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.373e+06, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.240e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.450e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+06, tolerance: 4.708e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.559e+05, tolerance: 3.606e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.533e+05, tolerance: 4.137e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+06, tolerance: 4.281e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+06, tolerance: 4.558e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elastic_regression__alpha</th>\n",
       "      <th>elastic_regression__l1_ratio</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>115700.337508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>115902.392141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>116443.528508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>116452.419582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>116925.964283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elastic_regression__alpha  elastic_regression__l1_ratio         scores\n",
       "34                        1.0                           0.8  115700.337508\n",
       "33                        1.0                           0.7  115902.392141\n",
       "32                        1.0                           0.6  116443.528508\n",
       "35                        1.0                           0.9  116452.419582\n",
       "18                        0.1                           0.1  116925.964283"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the five best numeric variables and their interactions with the one best categorical variable.\n",
    "\n",
    "X = baseball[[\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\", \"Division\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#tune lambdas/alphas to test multiple vals\n",
    "values = {\"elastic_regression__alpha\": [.001, .01, .1, 1, 10, 100],\n",
    "          \"elastic_regression__l1_ratio\": [.1, .2, .3, .4, .5, .6, .7, .8, .9]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_elastic, values, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df['scores'] = results_df['scores']*-1\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 Conclusion**\n",
    "\n",
    "From all the combinations of features and models, the best performing one is using an elastic regression with parameters alpha = 1 and l1_ratio = .8.\n",
    "\n",
    "The variables included in the model were five best numeric variables and their interactions with the one best categorical variable\n",
    "\n",
    "So in this case it was the following variables: \"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\", \"Division\"\n",
    "\n",
    "the MSE value I got for the best model (so the lowest MSE) is 115700.337508"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part III. Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Ridge**\n",
    "\n",
    "Compare your Ridge models with your ordinary regression models. How did your coefficients compare? Why does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For part 1 (every variable):\n",
    "ordinary regression outputs: \n",
    "r2: 0.3456645862518122\n",
    "\n",
    "ridge regression outputs:\n",
    "r2: 0.385012\n",
    "\n",
    "\n",
    "For Part 2 (for different various selection of variables):\n",
    "ordinary regression outputs: \n",
    "1. mse:  143812.9359162973\n",
    "2. mse:  121332.85377811702\n",
    "3. mse:  130401.97016858231\n",
    "\n",
    "ridge regression outputs:\n",
    "1. mse: 143658.517369\n",
    "2. mse: 119398.400113\n",
    "3. mse: 116972.675912\n",
    "\n",
    "Overall, the ridge regression models typically gave better performance when compared to the ordinary regression models. \n",
    "\n",
    "In terms of coefficients, for ridge regression the coefficients were typically smaller than those from ordianry regresion. This is be cause the ridge is introducing the penalty in which the penalty was shrinking coefficients toward 0. The reason that this makes sense is because this penalty will typically help with a few reasons (which are reducing multicollinearity and preventing overfitting of the model). So in the cases where there were many more varaibles in the model, we can see that the ridge regression method proved even more effective than the ordinary regression method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. LASSO**\n",
    "\n",
    "Compare your LASSO model in I with your three LASSO models in II. Did you get the same results? Why does this make sense? Did you get the same MSEs? Why does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For part 1 (every variable). lasso regression output:\n",
    "mse:  121828.14133338635\n",
    "\n",
    "For part 2 (model including the following variable selection).\n",
    "1. best numeric variable\n",
    "mse: 143793.449159\n",
    "2. top 5 numeric variable\n",
    "mse: 121332.402601\n",
    "3. top 5 numeric variable AND their corresponding interaction with the best categorical variable\n",
    "mse: 119129.330501\n",
    "\n",
    "The model including every variable had a very similiar mse to the model including the top 5 variable in part 2. With our last model in part 2 having the best mse score and first model in part 2 having the worst score out of all the lasso regressions.\n",
    "\n",
    "The differences we observe make sense because the LASSO regression is penalizing the less impactful variables (which can be done by shrinking their coefficients to 0). This resduced the model complexity and thus helps get better MSE values. We can see that especially see this happening for the model including every variable because many of the coefficients end up being 0 and we get a similiar score to a model that only used 5 variables as the predictor (but they were all considered effective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Elastic Net**\n",
    "\n",
    "Compare your MSEs for the Elastic Net models with those for the Ridge and LASSO models. Why does it make sense that Elastic Net always “wins”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elastic model mse scores\n",
    "part 1 (every variable):\n",
    "1. mse: 121500.81646251371\n",
    "\n",
    "For part 2 (model including the following variable selection).\n",
    "1. best numeric variable\n",
    "mse: 143655.076048\n",
    "2. top 5 numeric variable\n",
    "mse: 118839.350432\n",
    "3. top 5 numeric variable AND their corresponding interaction with the best categorical variable\n",
    "mse: 115700.337508\n",
    "\n",
    "Elastic net will always have an advantage over both the ridge and lasso methods because it combines them and optimizes.\n",
    "In part 1, the Elastic net did slightly better than the lasso (but not by much)\n",
    "\n",
    "In part 2 we can see that the elastic net method does better than ridge and lasso even when we only incorporated one variable (or many variables). Because the lasso and ridge models vary, it is hard to find a good balance for each, but because we are using gridsearch we are purposely optimizing to find the best combination to yield the highest mse score.\n",
    "\n",
    "In addition, how the elastic net combines both regression methods is by using both of their penalties. Thus elastic net is able to zero (if needed) out the irrelevent coefficients but is also able to keep the model stable and sometimes only minimize coefficients and keep too many (like ridge).\n",
    "\n",
    "This process of optimization is extremely particular to each individual model as well as the data being put through it, because of that there is no one perfect case that will fit any particular dataset and having that flexibility and generalization gives elastic net an edge over the other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part IV: Final Model**\n",
    "\n",
    "Fit your final best pipeline on the full dataset, and summarize your results in a few short sentences and a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "#interaction terms\n",
    "ct_inter = ColumnTransformer(\n",
    "  [\n",
    "    #i think this part makes it so that division by itself is not included in the model\n",
    "    (\"interaction_CRuns_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRuns\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_PutOuts_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__PutOuts\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Hits_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Hits\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_CRBI_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRBI\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Walks_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Walks\", \"dummify__Division_W\"]),\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ").set_output(transform = \"pandas\")\n",
    "\n",
    "#elastic pipeline\n",
    "lr_pipeline_elastic = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "   (\"interaction\", ct_inter),\n",
    "  #can now put our custom alpha and l1_ratio that we found in the previous step\n",
    "  (\"elastic_regression\", ElasticNet(alpha = 1, l1_ratio = .8))]\n",
    ").set_output(transform=\"pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.3702109391472586  mse:  121574.53101457682\n",
      "r2:  0.3702109391472586  mse:  121574.53101457682\n"
     ]
    }
   ],
   "source": [
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_elastic, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_elastic, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the pipeline did a decent job when fitting the full dataset. Although the MSE is a little bit higher, this is definitely something that is expected as there is a penalty for every beta we add. The model didn't do aswell as our best model found in part 3, but was definitely comparable (only off by around 3% in terms of R^2). Additionally, if we look back at our pipeline from part 1 (of the elastic net) we can see that it did slightly worse in score (lower by around 1% in terms of R^2). The fit we had for our pipeline was optimized for when we were using the five best numeric variables and their interactions with the one best categorical variable, but now that we have incorporated every variable in our dataset we can see it is not as effecient. We can also see this by the fact that we have different tuned hyperparameters from this pipeline versus the one found in part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residual Plot of Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model to the entire dataset\n",
    "lr_pipeline_elastic.fit(X, y)\n",
    "\n",
    "# Get predicted y values for the entire dataset\n",
    "lr_predicted_1 = lr_pipeline_elastic.predict(X)\n",
    "\n",
    "# Calculate residuals as the difference between actual and predicted values\n",
    "residuals = y - lr_predicted_1  # Ensure both y and lr_predicted_1 have the same shape\n",
    "\n",
    "# Plot residuals\n",
    "#aspect ratio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(lr_predicted_1, residuals, alpha=0.6, color=\"black\")\n",
    "#horizontal line\n",
    "plt.axhline(y=0, color=\"red\")\n",
    "#labs\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residual Plot of a Significantly Worst Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "#interaction terms\n",
    "ct_inter = ColumnTransformer(\n",
    "  [\n",
    "    #i think this part makes it so that division by itself is not included in the model\n",
    "    (\"interaction_CRuns_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRuns\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_PutOuts_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__PutOuts\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Hits_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Hits\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_CRBI_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRBI\", \"dummify__Division_W\"]),\n",
    "    (\"interaction_Walks_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Walks\", \"dummify__Division_W\"]),\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ").set_output(transform = \"pandas\")\n",
    "\n",
    "#elastic pipeline\n",
    "lr_pipeline_elastic = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "   (\"interaction\", ct_inter),\n",
    "  #can now put our custom alpha and l1_ratio that we found in the previous step\n",
    "  (\"elastic_regression\", ElasticNet(alpha = 100, l1_ratio = .2))]\n",
    ").set_output(transform=\"pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.025326461104620158  mse:  193114.28872800322\n",
      "r2:  0.025326461104620158  mse:  193114.28872800322\n"
     ]
    }
   ],
   "source": [
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_elastic, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_elastic, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model to the entire dataset\n",
    "lr_pipeline_elastic.fit(X, y)\n",
    "\n",
    "# Get predicted y values for the entire dataset\n",
    "lr_predicted_1 = lr_pipeline_elastic.predict(X)\n",
    "\n",
    "# Calculate residuals as the difference between actual and predicted values\n",
    "residuals = y - lr_predicted_1  # Ensure both y and lr_predicted_1 have the same shape\n",
    "\n",
    "# Plot residuals\n",
    "#aspect ratio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(lr_predicted_1, residuals, alpha=0.6, color=\"black\")\n",
    "#horizontal line\n",
    "plt.axhline(y=0, color=\"red\")\n",
    "#labs\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residual Plot Conclusion**\n",
    "\n",
    "From these plots we can see that the residual plot is a lot better for a model with a higher R^2 value, overall neither of these models are amazing, but it is definitely easy to see which one is better in this case.\n",
    "\n",
    "Some indictors to see if a model does better when plotting predicted values with their residual is that it is a lot more align with the the red horizontal line that I plotted (that is because that is where the residual would be 0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
