{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Lab 6 - Variable Selection and Regularization\n",
    "author: Ben Laufer\n",
    "format:\n",
    "    html:\n",
    "        code-fold: true\n",
    "embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "baseball = pd.read_csv('data/Hitters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AtBat         0\n",
      "Hits          0\n",
      "HmRun         0\n",
      "Runs          0\n",
      "RBI           0\n",
      "Walks         0\n",
      "Years         0\n",
      "CAtBat        0\n",
      "CHits         0\n",
      "CHmRun        0\n",
      "CRuns         0\n",
      "CRBI          0\n",
      "CWalks        0\n",
      "League        0\n",
      "Division      0\n",
      "PutOuts       0\n",
      "Assists       0\n",
      "Errors        0\n",
      "Salary       59\n",
      "NewLeague     0\n",
      "dtype: int64\n",
      "AtBat         0\n",
      "Hits          0\n",
      "HmRun         0\n",
      "Runs          0\n",
      "RBI           0\n",
      "Walks         0\n",
      "Years         0\n",
      "CAtBat        0\n",
      "CHits         0\n",
      "CHmRun        0\n",
      "CRuns         0\n",
      "CRBI          0\n",
      "CWalks        0\n",
      "League        0\n",
      "Division      0\n",
      "PutOuts       0\n",
      "Assists       0\n",
      "Errors        0\n",
      "Salary       59\n",
      "NewLeague     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Although it isn’t listed as a specific question, don’t forget to clean your data at the beginning. \n",
    "#How will you handle missing data?\n",
    "#Are there any variables that need adjusting?\n",
    "\n",
    "#clean data\n",
    "#find number of NA's per column\n",
    "na_counts = baseball.isna().sum()\n",
    "print(na_counts)\n",
    "\n",
    "#only NA's are salary\n",
    "#for now will choose to remove the observations where salary is NA\n",
    "baseball = baseball.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part I: Different Model Specs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Regression without regularization**\n",
    "\n",
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary linear regression\n",
    "\n",
    "2. Fit this pipeline to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "3. Use cross-validation to estimate the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary linear regression\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>League_A</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_E</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_A</th>\n",
       "      <th>NewLeague_N</th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.602900</td>\n",
       "      <td>-0.595675</td>\n",
       "      <td>-0.528551</td>\n",
       "      <td>-1.206112</td>\n",
       "      <td>-0.522063</td>\n",
       "      <td>-0.097527</td>\n",
       "      <td>1.397893</td>\n",
       "      <td>0.346791</td>\n",
       "      <td>0.174373</td>\n",
       "      <td>-0.002920</td>\n",
       "      <td>-0.121671</td>\n",
       "      <td>0.258966</td>\n",
       "      <td>0.435334</td>\n",
       "      <td>1.221499</td>\n",
       "      <td>-0.523191</td>\n",
       "      <td>0.213352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512542</td>\n",
       "      <td>0.492260</td>\n",
       "      <td>0.729966</td>\n",
       "      <td>0.441515</td>\n",
       "      <td>0.794060</td>\n",
       "      <td>1.609373</td>\n",
       "      <td>-0.901200</td>\n",
       "      <td>-0.452865</td>\n",
       "      <td>-0.409892</td>\n",
       "      <td>-0.076054</td>\n",
       "      <td>-0.415105</td>\n",
       "      <td>-0.199590</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>2.109109</td>\n",
       "      <td>-0.253863</td>\n",
       "      <td>0.819964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.628167</td>\n",
       "      <td>0.736490</td>\n",
       "      <td>0.958788</td>\n",
       "      <td>0.402286</td>\n",
       "      <td>1.026317</td>\n",
       "      <td>-0.189792</td>\n",
       "      <td>0.770868</td>\n",
       "      <td>1.301558</td>\n",
       "      <td>1.318174</td>\n",
       "      <td>1.898565</td>\n",
       "      <td>1.412051</td>\n",
       "      <td>1.572666</td>\n",
       "      <td>0.355654</td>\n",
       "      <td>-0.324661</td>\n",
       "      <td>-0.744179</td>\n",
       "      <td>-0.848219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.562092</td>\n",
       "      <td>-0.462459</td>\n",
       "      <td>-0.185319</td>\n",
       "      <td>-0.617673</td>\n",
       "      <td>-0.367225</td>\n",
       "      <td>-0.512719</td>\n",
       "      <td>-1.110209</td>\n",
       "      <td>-0.990935</td>\n",
       "      <td>-0.960153</td>\n",
       "      <td>-0.697693</td>\n",
       "      <td>-0.947521</td>\n",
       "      <td>-0.881228</td>\n",
       "      <td>-0.862315</td>\n",
       "      <td>1.840678</td>\n",
       "      <td>-0.543909</td>\n",
       "      <td>-0.696566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.294712</td>\n",
       "      <td>1.358167</td>\n",
       "      <td>-0.871783</td>\n",
       "      <td>0.755349</td>\n",
       "      <td>-0.018840</td>\n",
       "      <td>-0.282057</td>\n",
       "      <td>0.770868</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.634985</td>\n",
       "      <td>-0.612370</td>\n",
       "      <td>0.422846</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>-0.251434</td>\n",
       "      <td>-0.031177</td>\n",
       "      <td>2.087225</td>\n",
       "      <td>2.488147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   League_A  League_N  Division_E  Division_W  NewLeague_A  ...      CRBI    CWalks   PutOuts   Assists    Errors\n",
       "0       0.0       1.0         0.0         1.0          0.0  ...  0.258966  0.435334  1.221499 -0.523191  0.213352\n",
       "1       1.0       0.0         0.0         1.0          1.0  ... -0.199590  0.010373  2.109109 -0.253863  0.819964\n",
       "2       0.0       1.0         1.0         0.0          0.0  ...  1.572666  0.355654 -0.324661 -0.744179 -0.848219\n",
       "3       0.0       1.0         1.0         0.0          0.0  ... -0.881228 -0.862315  1.840678 -0.543909 -0.696566\n",
       "4       1.0       0.0         0.0         1.0          1.0  ...  0.017294 -0.251434 -0.031177  2.087225  2.488147\n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the data\n",
    "X_1 = ct.fit_transform(X)\n",
    "\n",
    "# Retrieve feature names\n",
    "#REFRENCED CHAT GPT TO GET COLUMN NAMES TO MAKE SURE ALL COLS WERE SELECTED\n",
    "ohe_feature_names = ct.named_transformers_['dummify'].get_feature_names_out(X.select_dtypes(include='object').columns)\n",
    "num_feature_names = X.select_dtypes(include=np.number).columns\n",
    "all_feature_names = np.concatenate([ohe_feature_names, num_feature_names])\n",
    "\n",
    "# Create a DataFrame with the transformed data\n",
    "X_1_df = pd.DataFrame(X_1, columns=all_feature_names)\n",
    "X_1_df.head()\n",
    "\n",
    "#all columns are there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>League_A</td>\n",
       "      <td>-31.299712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>League_N</td>\n",
       "      <td>31.299712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Division_E</td>\n",
       "      <td>58.424623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Division_W</td>\n",
       "      <td>-58.424623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewLeague_A</td>\n",
       "      <td>12.381163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NewLeague_N</td>\n",
       "      <td>-12.381163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>-291.094556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits</td>\n",
       "      <td>337.830479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>37.853837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Runs</td>\n",
       "      <td>-60.572479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RBI</td>\n",
       "      <td>-26.994984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walks</td>\n",
       "      <td>135.073897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years</td>\n",
       "      <td>-16.693359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>-391.038655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHits</td>\n",
       "      <td>86.687617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHmRun</td>\n",
       "      <td>-14.181723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>480.747135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>260.689886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>-213.892259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>78.761296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Assists</td>\n",
       "      <td>53.732490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Errors</td>\n",
       "      <td>-22.160862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Coefficient\n",
       "0      League_A   -31.299712\n",
       "1      League_N    31.299712\n",
       "2    Division_E    58.424623\n",
       "3    Division_W   -58.424623\n",
       "4   NewLeague_A    12.381163\n",
       "5   NewLeague_N   -12.381163\n",
       "6         AtBat  -291.094556\n",
       "7          Hits   337.830479\n",
       "8         HmRun    37.853837\n",
       "9          Runs   -60.572479\n",
       "10          RBI   -26.994984\n",
       "11        Walks   135.073897\n",
       "12        Years   -16.693359\n",
       "13       CAtBat  -391.038655\n",
       "14        CHits    86.687617\n",
       "15       CHmRun   -14.181723\n",
       "16        CRuns   480.747135\n",
       "17         CRBI   260.689886\n",
       "18       CWalks  -213.892259\n",
       "19      PutOuts    78.761296\n",
       "20      Assists    53.732490\n",
       "21       Errors   -22.160862"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline to the full dataset\n",
    "lr_pipeline_1.fit(X, y)\n",
    "\n",
    "# Get feature names from the ColumnTransformer\n",
    "#REFRENCED CHAT GPT TO GET COLUMN NAMES TO MAKE SURE ALL COLS WERE SELECTED\n",
    "ohe_feature_names = ct.named_transformers_['dummify'].get_feature_names_out(X.select_dtypes(include='object').columns)\n",
    "num_feature_names = X.select_dtypes(include=np.number).columns\n",
    "all_feature_names = np.concatenate([ohe_feature_names, num_feature_names])\n",
    "\n",
    "# Get coefficients from the linear regression model\n",
    "coefficients = lr_pipeline_1.named_steps[\"linear_regression\"].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and their corresponding coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    \"Feature\": all_feature_names,\n",
    "    \"Coefficient\": coefficients\n",
    "})\n",
    "\n",
    "# Display the top coefficients\n",
    "coeff_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most important coefficients in this case, we see that we have all the categorical options for all the dummy variables we converted. So in order to accurately estimate that we would find the total amount between the two groups.\n",
    "\n",
    "For instance for league_N and league_A: A player's salary is estimated to make 31.299712+31.299712=62.599424 thousand MORE if they play in the A league versus the N league. This would work the same for the NewLeague dummy variable as well as the Division dummy variable.\n",
    "\n",
    "The highest coefficients we see in our models are CRuns: 480, Hits: 337 and CAtBat: -391\n",
    "\n",
    "CRuns: For every 1 standard deviation increase in number of home runs during a player's career, there is an estimated 480 (thousand) increase in that players salary\n",
    "\n",
    "Hits: For every 1 standard deviation increase in the player's number of hits in 1986, there is an estimated 337 (thousand) increase in that players salary\n",
    "\n",
    "CAtBat: For every 1 standard deviation increase in the player's number of times at bar during their career, there is an estimated -391 (thousand) DECREASE in that players salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.33940791514294444  mse:  121556.06500734284\n",
      "r2:  0.33940791514294444  mse:  121556.06500734284\n"
     ]
    }
   ],
   "source": [
    "#Use cross-validation to estimate the MSE you would expect if you used this pipeline to predict 1989 salaries.\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_1, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_1, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Ridge regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression\n",
    "\n",
    "2. Use cross-validation to tune the lambda hyperparameter.\n",
    "\n",
    "3. Fit the pipeline with your chosen to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "4. Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"ridge_regression\", Ridge(alpha = 1))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ridge_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.385012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.368328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.355767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.347675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.344084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.343556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ridge_regression__alpha    scores\n",
       "5                  100.000  0.385012\n",
       "4                   10.000  0.368328\n",
       "3                    1.000  0.355767\n",
       "2                    0.100  0.347675\n",
       "1                    0.010  0.344084\n",
       "0                    0.001  0.343556"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use cross-validation to tune the hyperparameter.\n",
    "\n",
    "#tune lambdas to test multiple vals\n",
    "lambdas = {\"ridge_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_1, lambdas, cv = 5, scoring='r2')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the pipeline with your chosen to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_linear = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  #changed alpha = 100\n",
    "  (\"ridge_regression\", Ridge(alpha = 100))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>League_A</td>\n",
       "      <td>-11.051842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>League_N</td>\n",
       "      <td>11.051842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Division_E</td>\n",
       "      <td>38.023222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Division_W</td>\n",
       "      <td>-38.023222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewLeague_A</td>\n",
       "      <td>-4.091590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NewLeague_N</td>\n",
       "      <td>4.091590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>-0.567370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits</td>\n",
       "      <td>49.612386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>-1.464159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Runs</td>\n",
       "      <td>29.343263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RBI</td>\n",
       "      <td>22.958015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walks</td>\n",
       "      <td>41.384617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years</td>\n",
       "      <td>-2.708306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>24.705844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHits</td>\n",
       "      <td>44.534276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHmRun</td>\n",
       "      <td>38.685330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>45.507606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>47.145556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>4.036371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>56.881522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Assists</td>\n",
       "      <td>7.457239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Errors</td>\n",
       "      <td>-13.382390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Coefficient\n",
       "0      League_A   -11.051842\n",
       "1      League_N    11.051842\n",
       "2    Division_E    38.023222\n",
       "3    Division_W   -38.023222\n",
       "4   NewLeague_A    -4.091590\n",
       "5   NewLeague_N     4.091590\n",
       "6         AtBat    -0.567370\n",
       "7          Hits    49.612386\n",
       "8         HmRun    -1.464159\n",
       "9          Runs    29.343263\n",
       "10          RBI    22.958015\n",
       "11        Walks    41.384617\n",
       "12        Years    -2.708306\n",
       "13       CAtBat    24.705844\n",
       "14        CHits    44.534276\n",
       "15       CHmRun    38.685330\n",
       "16        CRuns    45.507606\n",
       "17         CRBI    47.145556\n",
       "18       CWalks     4.036371\n",
       "19      PutOuts    56.881522\n",
       "20      Assists     7.457239\n",
       "21       Errors   -13.382390"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output all variables coeff.\n",
    "# Fit the pipeline to the full dataset\n",
    "lr_pipeline_linear.fit(X, y)\n",
    "\n",
    "# Get feature names from the ColumnTransformer\n",
    "#REFRENCED CHAT GPT TO GET COLUMN NAMES TO MAKE SURE ALL COLS WERE SELECTED\n",
    "ohe_feature_names = ct.named_transformers_['dummify'].get_feature_names_out(X.select_dtypes(include='object').columns)\n",
    "num_feature_names = X.select_dtypes(include=np.number).columns\n",
    "all_feature_names = np.concatenate([ohe_feature_names, num_feature_names])\n",
    "\n",
    "# Get coefficients from the linear regression model\n",
    "coefficients = lr_pipeline_linear.named_steps[\"ridge_regression\"].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and their corresponding coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    \"Feature\": all_feature_names,\n",
    "    \"Coefficient\": coefficients\n",
    "})\n",
    "\n",
    "# Display the top coefficients\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main changes we see are that a lot of the very large coefficients of variables have changed (specifically CRuns, Hits, and CAtBat). Additionally, the coefficient for CAtBat is now positive!\n",
    "\n",
    "CRuns: For every 1 standard deviation increase in number of home runs during a player's career, there is an estimated 44.53 (thousand) increase in that players salary\n",
    "\n",
    "Hits: For every 1 standard deviation increase in the player's number of hits in 1986, there is an estimated 49.61 (thousand) increase in that players salary\n",
    "\n",
    "CAtBat: For every 1 standard deviation increase in the player's number of times at bar during their career, there is an estimated 24.70 (thousand) INCREASE in that players salary)\n",
    "\n",
    "Overall most of the coefficients of our predictors are lower.\n",
    "\n",
    "Some of the other most important coefficients now include PutOuts and CRBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.38501221231517163  mse:  120716.43558937623\n",
      "r2:  0.38501221231517163  mse:  120716.43558937623\n"
     ]
    }
   ],
   "source": [
    "#Report the MSE you would expect if you used this pipeline to predict 1989 salaries.\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Lasso Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression\n",
    "\n",
    "2. Use cross-validation to tune the alpha hyperparameter.\n",
    "\n",
    "3. Fit the pipeline with your chosen to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "4. Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary lasso regression\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"lasso_regression\", Ridge(alpha = 1))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_regression__alpha</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.385012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.368328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.355767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.347675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.344084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.343556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lasso_regression__alpha    scores\n",
       "5                  100.000  0.385012\n",
       "4                   10.000  0.368328\n",
       "3                    1.000  0.355767\n",
       "2                    0.100  0.347675\n",
       "1                    0.010  0.344084\n",
       "0                    0.001  0.343556"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use cross-validation to tune the hyperparameter.\n",
    "\n",
    "#tune lambdas to test multiple vals\n",
    "lambdas = {\"lasso_regression__alpha\": [.001, .01, .1, 1, 10, 100]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_1, lambdas, cv = 5, scoring='r2')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the pipeline with your chosen to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_lasso = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  #changed alpha = 100\n",
    "  (\"lasso_regression\", Ridge(alpha = 100))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>League_A</td>\n",
       "      <td>-11.051842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>League_N</td>\n",
       "      <td>11.051842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Division_E</td>\n",
       "      <td>38.023222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Division_W</td>\n",
       "      <td>-38.023222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewLeague_A</td>\n",
       "      <td>-4.091590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NewLeague_N</td>\n",
       "      <td>4.091590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>-0.567370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits</td>\n",
       "      <td>49.612386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>-1.464159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Runs</td>\n",
       "      <td>29.343263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RBI</td>\n",
       "      <td>22.958015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walks</td>\n",
       "      <td>41.384617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years</td>\n",
       "      <td>-2.708306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>24.705844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHits</td>\n",
       "      <td>44.534276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHmRun</td>\n",
       "      <td>38.685330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>45.507606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>47.145556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>4.036371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>56.881522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Assists</td>\n",
       "      <td>7.457239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Errors</td>\n",
       "      <td>-13.382390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Coefficient\n",
       "0      League_A   -11.051842\n",
       "1      League_N    11.051842\n",
       "2    Division_E    38.023222\n",
       "3    Division_W   -38.023222\n",
       "4   NewLeague_A    -4.091590\n",
       "5   NewLeague_N     4.091590\n",
       "6         AtBat    -0.567370\n",
       "7          Hits    49.612386\n",
       "8         HmRun    -1.464159\n",
       "9          Runs    29.343263\n",
       "10          RBI    22.958015\n",
       "11        Walks    41.384617\n",
       "12        Years    -2.708306\n",
       "13       CAtBat    24.705844\n",
       "14        CHits    44.534276\n",
       "15       CHmRun    38.685330\n",
       "16        CRuns    45.507606\n",
       "17         CRBI    47.145556\n",
       "18       CWalks     4.036371\n",
       "19      PutOuts    56.881522\n",
       "20      Assists     7.457239\n",
       "21       Errors   -13.382390"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output all variables coeff.\n",
    "# Fit the pipeline to the full dataset\n",
    "lr_pipeline_lasso.fit(X, y)\n",
    "\n",
    "# Get feature names from the ColumnTransformer\n",
    "#REFRENCED CHAT GPT TO GET COLUMN NAMES TO MAKE SURE ALL COLS WERE SELECTED\n",
    "ohe_feature_names = ct.named_transformers_['dummify'].get_feature_names_out(X.select_dtypes(include='object').columns)\n",
    "num_feature_names = X.select_dtypes(include=np.number).columns\n",
    "all_feature_names = np.concatenate([ohe_feature_names, num_feature_names])\n",
    "\n",
    "# Get coefficients from the linear regression model\n",
    "coefficients = lr_pipeline_lasso.named_steps[\"lasso_regression\"].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and their corresponding coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    \"Feature\": all_feature_names,\n",
    "    \"Coefficient\": coefficients\n",
    "})\n",
    "\n",
    "# Display the top coefficients\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the ridge regressiom pipeline, the main changes we see are that a lot of the very large coefficients of variables have changed (specifically CRuns, Hits, and CAtBat). Additionally, the coefficient for CAtBat is now positive!\n",
    "\n",
    "The main difference is that the numbers have changed by a little but still no major changes. (With Hits and CAtBat staying the same exact value)\n",
    "\n",
    "CRuns: For every 1 standard deviation increase in number of home runs during a player's career, there is an estimated 45.50 (thousand) increase in that players salary\n",
    "\n",
    "Hits: For every 1 standard deviation increase in the player's number of hits in 1986, there is an estimated 49.61 (thousand) increase in that players salary\n",
    "\n",
    "CAtBat: For every 1 standard deviation increase in the player's number of times at bar during their career, there is an estimated 24.70 (thousand) INCREASE in that players salary)\n",
    "\n",
    "Overall most of the coefficients of our predictors are lower.\n",
    "\n",
    "Some of the other most important coefficients now include PutOuts and CRBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.38501221231517163  mse:  120716.43558937623\n",
      "r2:  0.38501221231517163  mse:  120716.43558937623\n"
     ]
    }
   ],
   "source": [
    "#Report the MSE you would expect if you used this pipeline to predict 1989 salaries.\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_lasso, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_lasso, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D. Elastic Net**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary elastic net regression\n",
    "\n",
    "2. Use cross-validation to tune the lambda and alpha hyperparameters.\n",
    "\n",
    "3. Fit the pipeline with your chosen hyperparameters to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "4. Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary elastic net regression\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_1 = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  (\"elastic_regression\", ElasticNet(alpha = .01, l1_ratio = .5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+07, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.137e+06, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.359e+06, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.710e+06, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+07, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.075e+06, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+07, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.278e+06, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.657e+06, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.035e+06, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+07, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.206e+06, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.621e+06, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+07, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.010e+06, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+07, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.136e+06, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.596e+06, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.995e+06, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+07, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.060e+06, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.579e+06, tolerance: 4.558e+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.986e+06, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+07, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.963e+06, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.566e+06, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+07, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+06, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+07, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.816e+06, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.557e+06, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+07, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.981e+06, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+07, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.525e+06, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.550e+06, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+07, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+06, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+07, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.488e+06, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.543e+06, tolerance: 4.558e+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.601e+03, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+05, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+04, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.270e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.610e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.133e+05, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.634e+04, tolerance: 3.606e+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.792e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.632e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.947e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.597e+05, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.940e+05, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.672e+06, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.925e+05, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.683e+05, tolerance: 4.558e+03\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elastic_regression__alpha</th>\n",
       "      <th>elastic_regression__l1_ratio</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.386643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.386557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.386511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.386203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.385538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.384429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.383699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.382184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.378885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.374385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.372547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.371741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.371415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.370860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.369877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.368760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.367384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.365729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.363218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.359460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.358668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.358095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.357472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.356785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.356192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.356012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.355114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.354020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.352559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.350188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.349742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.349358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.348935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.348468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.347949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.347370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.346719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.345986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.345157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.340031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.323995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.308553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.293957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.280257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.267491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.144923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.092232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.066016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.050312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.039867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.032448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.026902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.022617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.019155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elastic_regression__alpha  elastic_regression__l1_ratio    scores\n",
       "28                      1.000                           0.2  0.386643\n",
       "29                      1.000                           0.3  0.386557\n",
       "27                      1.000                           0.1  0.386511\n",
       "30                      1.000                           0.4  0.386203\n",
       "31                      1.000                           0.5  0.385538\n",
       "32                      1.000                           0.6  0.384429\n",
       "44                     10.000                           0.9  0.383699\n",
       "33                      1.000                           0.7  0.382184\n",
       "34                      1.000                           0.8  0.378885\n",
       "35                      1.000                           0.9  0.374385\n",
       "18                      0.100                           0.1  0.372547\n",
       "19                      0.100                           0.2  0.371741\n",
       "43                     10.000                           0.8  0.371415\n",
       "20                      0.100                           0.3  0.370860\n",
       "21                      0.100                           0.4  0.369877\n",
       "22                      0.100                           0.5  0.368760\n",
       "23                      0.100                           0.6  0.367384\n",
       "24                      0.100                           0.7  0.365729\n",
       "25                      0.100                           0.8  0.363218\n",
       "26                      0.100                           0.9  0.359460\n",
       "9                       0.010                           0.1  0.358668\n",
       "10                      0.010                           0.2  0.358095\n",
       "11                      0.010                           0.3  0.357472\n",
       "12                      0.010                           0.4  0.356785\n",
       "42                     10.000                           0.7  0.356192\n",
       "13                      0.010                           0.5  0.356012\n",
       "14                      0.010                           0.6  0.355114\n",
       "15                      0.010                           0.7  0.354020\n",
       "16                      0.010                           0.8  0.352559\n",
       "17                      0.010                           0.9  0.350188\n",
       "0                       0.001                           0.1  0.349742\n",
       "1                       0.001                           0.2  0.349358\n",
       "2                       0.001                           0.3  0.348935\n",
       "3                       0.001                           0.4  0.348468\n",
       "4                       0.001                           0.5  0.347949\n",
       "5                       0.001                           0.6  0.347370\n",
       "6                       0.001                           0.7  0.346719\n",
       "7                       0.001                           0.8  0.345986\n",
       "8                       0.001                           0.9  0.345157\n",
       "41                     10.000                           0.6  0.340031\n",
       "40                     10.000                           0.5  0.323995\n",
       "39                     10.000                           0.4  0.308553\n",
       "38                     10.000                           0.3  0.293957\n",
       "37                     10.000                           0.2  0.280257\n",
       "36                     10.000                           0.1  0.267491\n",
       "53                    100.000                           0.9  0.144923\n",
       "52                    100.000                           0.8  0.092232\n",
       "51                    100.000                           0.7  0.066016\n",
       "50                    100.000                           0.6  0.050312\n",
       "49                    100.000                           0.5  0.039867\n",
       "48                    100.000                           0.4  0.032448\n",
       "47                    100.000                           0.3  0.026902\n",
       "46                    100.000                           0.2  0.022617\n",
       "45                    100.000                           0.1  0.019155"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use cross-validation to tune the lambda and alpha hyperparameters.\n",
    "\n",
    "#Use cross-validation to tune the hyperparameter.\n",
    "\n",
    "#tune lambdas/alphas to test multiple vals\n",
    "values = {\"elastic_regression__alpha\": [.001, .01, .1, 1, 10, 100],\n",
    "          \"elastic_regression__l1_ratio\": [.1, .2, .3, .4, .5, .6, .7, .8, .9]}\n",
    "\n",
    "gscv = GridSearchCV(lr_pipeline_1, values, cv = 5, scoring='r2')\n",
    "\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "params_df = pd.DataFrame(gscv_fitted.cv_results_['params'])\n",
    "\n",
    "results_df = params_df.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "\n",
    "results_df.sort_values(by = 'scores', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the pipeline with your chosen hyperparameters to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "X = baseball.drop([\"Salary\"], axis = 1)\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    #handle_unknown: ignore observations for unknown values in category variable\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lr_pipeline_elastic = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "  #can now put our custom alpha and l1_ratio that we found in the previous step\n",
    "  (\"elastic_regression\", ElasticNet(alpha = 1, l1_ratio = .2))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>League_A</td>\n",
       "      <td>-7.248569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>League_N</td>\n",
       "      <td>7.248595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Division_E</td>\n",
       "      <td>26.103984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Division_W</td>\n",
       "      <td>-26.103971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewLeague_A</td>\n",
       "      <td>-4.116523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NewLeague_N</td>\n",
       "      <td>4.116546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>12.179419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits</td>\n",
       "      <td>37.450668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HmRun</td>\n",
       "      <td>5.609999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Runs</td>\n",
       "      <td>27.011028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RBI</td>\n",
       "      <td>22.983192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walks</td>\n",
       "      <td>34.568563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years</td>\n",
       "      <td>7.634212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>25.867403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHits</td>\n",
       "      <td>36.124822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHmRun</td>\n",
       "      <td>32.312440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>36.943114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>37.880465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>15.355773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>44.835142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Assists</td>\n",
       "      <td>3.836558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Errors</td>\n",
       "      <td>-8.036185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Coefficient\n",
       "0      League_A    -7.248569\n",
       "1      League_N     7.248595\n",
       "2    Division_E    26.103984\n",
       "3    Division_W   -26.103971\n",
       "4   NewLeague_A    -4.116523\n",
       "5   NewLeague_N     4.116546\n",
       "6         AtBat    12.179419\n",
       "7          Hits    37.450668\n",
       "8         HmRun     5.609999\n",
       "9          Runs    27.011028\n",
       "10          RBI    22.983192\n",
       "11        Walks    34.568563\n",
       "12        Years     7.634212\n",
       "13       CAtBat    25.867403\n",
       "14        CHits    36.124822\n",
       "15       CHmRun    32.312440\n",
       "16        CRuns    36.943114\n",
       "17         CRBI    37.880465\n",
       "18       CWalks    15.355773\n",
       "19      PutOuts    44.835142\n",
       "20      Assists     3.836558\n",
       "21       Errors    -8.036185"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output all variables coeff.\n",
    "# Fit the pipeline to the full dataset\n",
    "lr_pipeline_elastic.fit(X, y)\n",
    "\n",
    "# Get feature names from the ColumnTransformer\n",
    "#REFRENCED CHAT GPT TO GET COLUMN NAMES TO MAKE SURE ALL COLS WERE SELECTED\n",
    "ohe_feature_names = ct.named_transformers_['dummify'].get_feature_names_out(X.select_dtypes(include='object').columns)\n",
    "num_feature_names = X.select_dtypes(include=np.number).columns\n",
    "all_feature_names = np.concatenate([ohe_feature_names, num_feature_names])\n",
    "\n",
    "# Get coefficients from the linear regression model\n",
    "coefficients = lr_pipeline_elastic.named_steps[\"elastic_regression\"].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and their corresponding coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    \"Feature\": all_feature_names,\n",
    "    \"Coefficient\": coefficients\n",
    "})\n",
    "\n",
    "# Display the top coefficients\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elastic regression with parameters lambda = 1 and l1_ratio = .2 definitely has similiar coefficients to the previous steps (that is because the elastic regression uses a combination of two calculations to find its own penalty formula) Where that ratio of which type is more effective is determined by the l1_ratio.\n",
    "\n",
    "Because 0 would mean a pure ridge regression and 1 would mean a pure lasso regression\n",
    "\n",
    "that means that essentially 80% of the penalty weight is on a ridge penalty and 20% is on a lasso penalty. As a result we can see that are values are a lot more similiar to the ridge regression, (even though we used a completely different alpha value)\n",
    "\n",
    "Some of the most notable coefficient changes from the previous regression (lasso) are that CWalks has tripled. CRBI, CRuns, Walks, Hits, and CHits are all lower.\n",
    "\n",
    "Interpretation of CWalks output: For every 1 standard deviation increase in a players number of walks in 1986, their salary is expected to increase by 34.56 (thousand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.3866433466516487  mse:  121500.81646251371\n",
      "r2:  0.3866433466516487  mse:  121500.81646251371\n"
     ]
    }
   ],
   "source": [
    "#Report the MSE you would expect if you used this pipeline to predict 1989 salaries.\n",
    "\n",
    "#Report the MSE you would expect if you used this pipeline to predict 1989 salaries.\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_elastic, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_elastic, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)\n",
    "\n",
    "#this combination has given us the highest R^2 and lowest MSE compared to all the previous regression with their corresponding hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part II. Variable Selection**\n",
    "\n",
    "Based on the above results, decide on:\n",
    "\n",
    "- Which numeric variable is most important.\n",
    "\n",
    "- Which five numeric variables are most important\n",
    "\n",
    "- Which categorical variable is most important\n",
    "\n",
    "For each of the four model specifications, compare the following possible feature sets:\n",
    "\n",
    "1. Using only the one best numeric variable.\n",
    "\n",
    "2. Using only the five best variables.\n",
    "\n",
    "3. Using the five best numeric variables and their interactions with the one best categorical variable.\n",
    "\n",
    "Report which combination of features and model performed best, based on the validation metric of MSE.\n",
    "\n",
    "(Note: \n",
    " and \n",
    " must be re-tuned for each feature set.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable Selection**\n",
    "\n",
    "1. Most Important Numeric Variable: CRuns\n",
    "\n",
    "2. Top 5 Most Important Numeric Variables: CRuns, PutOuts, Hits, CRBI, Walks\n",
    "\n",
    "3. Most Important Categorical Variable: Division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Regression without regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.266884498380676  mse:  148807.7834751813\n",
      "r2:  0.266884498380676  mse:  148807.7834751813\n"
     ]
    }
   ],
   "source": [
    "#Using only the one best numeric variable.\n",
    "X = baseball[[\"CRuns\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.4000670374532286  mse:  119398.40011345323\n",
      "r2:  0.4000670374532286  mse:  119398.40011345323\n"
     ]
    }
   ],
   "source": [
    "#Using only the five best variables.\n",
    "X = baseball[[\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the five best numeric variables and their interactions with the one best categorical variable.\n",
    "\n",
    "X = baseball[[\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\", \"Division\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    #drop = \"first\" should make it so that division is not included in the model\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False, drop = \"first\"), [\"Division\"]),\n",
    "    (\"standardize\", StandardScaler(), [\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\"]),\n",
    "  ],\n",
    "  remainder = \"drop\"\n",
    ")\n",
    "\n",
    "#interaction terms\n",
    "ct_inter = ColumnTransformer(\n",
    "  [\n",
    "    #i think this part makes it so that division by itself is not included in the model\n",
    "    (\"interaction_CRuns_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRuns\", \"dummify__Division_E\"]),\n",
    "    #(\"interaction_PutOuts_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__PutOuts\", \"dummify__Division_E\"]),\n",
    "    #(\"interaction_Hits_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Hits\", \"dummify__Division_E\"]),\n",
    "    #(\"interaction_CRBI_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__CRBI\", \"dummify__Division_E\"]),\n",
    "    #(\"interaction_Walks_Division\", PolynomialFeatures(degree=2, interaction_only = True, include_bias=False), [\"standardize__Walks\", \"dummify__Division_E\"]),\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ").set_output(transform = \"pandas\")\n",
    "\n",
    "\n",
    "lr_pipeline_linear = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "   (\"interaction\", ct_inter),\n",
    "  (\"linear_regression\", LinearRegression())]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/__init__.py\", line 482, in _get_column_indices\n    all_columns = X.columns\n                  ^^^^^^^^^\nAttributeError: 'numpy.ndarray' object has no attribute 'columns'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 906, in fit_transform\n    self._validate_column_callables(X)\n  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 496, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/__init__.py\", line 484, in _get_column_indices\n    raise ValueError(\nValueError: Specifying the columns using strings is only supported for dataframes.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[121], line 3\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#score how well the model did\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#R^2\u001b[39;00m\n",
      "\u001b[0;32m----> 3\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_val_score(lr_pipeline_linear, X, y, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m      4\u001b[0m r2 \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#MSE\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[1;32m    211\u001b[0m         )\n",
      "\u001b[1;32m    212\u001b[0m     ):\n",
      "\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n",
      "\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n",
      "\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n",
      "\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n",
      "\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n",
      "\u001b[1;32m    223\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n",
      "\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n",
      "\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n",
      "\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n",
      "\u001b[1;32m    720\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n",
      "\u001b[1;32m    721\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n",
      "\u001b[1;32m    722\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n",
      "\u001b[1;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n",
      "\u001b[1;32m    724\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n",
      "\u001b[1;32m    725\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n",
      "\u001b[1;32m    726\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n",
      "\u001b[1;32m    727\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n",
      "\u001b[1;32m    728\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n",
      "\u001b[1;32m    729\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n",
      "\u001b[1;32m    730\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n",
      "\u001b[1;32m    731\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n",
      "\u001b[1;32m    732\u001b[0m )\n",
      "\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[1;32m    211\u001b[0m         )\n",
      "\u001b[1;32m    212\u001b[0m     ):\n",
      "\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n",
      "\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n",
      "\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n",
      "\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n",
      "\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n",
      "\u001b[1;32m    223\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:450\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n",
      "\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n",
      "\u001b[1;32m    430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n",
      "\u001b[1;32m    431\u001b[0m     delayed(_fit_and_score)(\n",
      "\u001b[1;32m    432\u001b[0m         clone(estimator),\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n",
      "\u001b[1;32m    448\u001b[0m )\n",
      "\u001b[0;32m--> 450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n",
      "\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n",
      "\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n",
      "\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n",
      "\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n",
      "\u001b[1;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[1;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    535\u001b[0m     )\n",
      "\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n",
      "\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[1;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    546\u001b[0m     )\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/__init__.py\", line 482, in _get_column_indices\n",
      "    all_columns = X.columns\n",
      "                  ^^^^^^^^^\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'columns'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 906, in fit_transform\n",
      "    self._validate_column_callables(X)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 496, in _validate_column_callables\n",
      "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/__init__.py\", line 484, in _get_column_indices\n",
      "    raise ValueError(\n",
      "ValueError: Specifying the columns using strings is only supported for dataframes.\n"
     ]
    }
   ],
   "source": [
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.42731129570461857\n",
      "MSE:  105677.17614174394\n",
      "R^2:  0.42731129570461857\n",
      "MSE:  105677.17614174394\n"
     ]
    }
   ],
   "source": [
    "# Define feature matrix and target variable\n",
    "X = baseball[[\"CRuns\", \"PutOuts\", \"Hits\", \"CRBI\", \"Walks\", \"Division\"]]\n",
    "y = baseball[\"Salary\"]\n",
    "\n",
    "# Preprocessing with automatic column selection\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        # One-hot encode the categorical variable\n",
    "        (\"dummify\", OneHotEncoder(sparse_output=False, drop=\"first\"), make_column_selector(dtype_include=\"object\")),\n",
    "        \n",
    "        # Standardize numeric features\n",
    "        (\"standardize\", StandardScaler(), make_column_selector(dtype_include=\"number\"))\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Full pipeline with PolynomialFeatures for interaction terms\n",
    "lr_pipeline_linear = Pipeline([\n",
    "    (\"preprocessing\", ct),\n",
    "    #interactions?\n",
    "    (\"interaction\", PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    (\"linear_regression\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.42731129570461857  mse:  105677.17614174394\n",
      "r2:  0.42731129570461857  mse:  105677.17614174394\n"
     ]
    }
   ],
   "source": [
    "#score how well the model did\n",
    "#R^2\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='r2')\n",
    "r2 = scores.mean()\n",
    "\n",
    "#MSE\n",
    "scores = cross_val_score(lr_pipeline_linear, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse = scores.mean()*-1\n",
    "\n",
    "print(\"r2: \", r2, \" mse: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Ridge regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Lasso Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D. Elastic Net**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
