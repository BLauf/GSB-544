{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2775680049.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n",
      "\u001b[0;31m    ---\u001b[0m\n",
      "\u001b[0m       ^\u001b[0m\n",
      "\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "---\n",
    "\n",
    "title: Lab 4 - Coffee Lovers Unite\n",
    "author: Ben Laufer\n",
    "format:\n",
    "    html:\n",
    "        code-fold: true\n",
    "embed-resources: true\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coffee Lovers Unite!**\n",
    "If caffeine is one of the most popular drugs, then coffee is likely one of the most popular delivery systems for it. Aside from caffeine, people enjoy the wonderful variety of coffee-related drinks. Let’s do a rough investigation of the “market share” by two of the top coffee chains in the United States!\n",
    "\n",
    "World Population Review provides some great data on store locations and chain prevalence. Check out this page for the Starbucks Coffee locations in the United States. Notice that this page only really gives the name of the state and the number of locations in that state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scrape the Location Counts**\n",
    "\n",
    "1. Use the beautifulsoup library to scrape the data (from the link above) on state names and corresponding number of store locations, for the following chains:\n",
    "- Starbucks\n",
    "- Dunkin’ Donuts\n",
    "\n",
    "2. Parse, merge and tidy your data. Think carefully about what the tidy version of this dataset is with multiple years represented on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 (STARBUCKS)\n",
    "#requests\n",
    "sb_response = requests.get(\"https://worldpopulationreview.com/state-rankings/starbucks-stores-by-state\")\n",
    "\n",
    "#soup\n",
    "sb_soup = BeautifulSoup(sb_response.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table (dont want table to be a list)\n",
    "sb_table = sb_soup.find(\"table\",\n",
    "                    attrs={\n",
    "                      \"class\": \"wpr-table\"}\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>2023</th>\n",
       "      <th>2021</th>\n",
       "      <th>2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>3,080</td>\n",
       "      <td>2,959</td>\n",
       "      <td>3,117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>1,346</td>\n",
       "      <td>1,215</td>\n",
       "      <td>1,409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>844</td>\n",
       "      <td>786</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington</td>\n",
       "      <td>741</td>\n",
       "      <td>739</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>692</td>\n",
       "      <td>643</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state   2023   2021   2024\n",
       "0  California  3,080  2,959  3,117\n",
       "1       Texas  1,346  1,215  1,409\n",
       "2     Florida    844    786    892\n",
       "3  Washington    741    739    736\n",
       "4    New York    692    643    715"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn html into actual dataframe\n",
    "\n",
    "# initialize an empty list\n",
    "rows = []\n",
    "\n",
    "# iterate over all rows in the city table\n",
    "#we do 1: b/c there is only 1 header row in this data\n",
    "for state in sb_table.find_all(\"tr\")[1:]:\n",
    "\n",
    "    # Get all the cells (<th>) and (<td>) in the row.\n",
    "    cells_state = state.find_all(\"th\")\n",
    "    cells_obs = state.find_all(\"td\")\n",
    "    \n",
    "    # Find the the name of the state in cell[0]\n",
    "    # which for most state is contained in the <a> tag\n",
    "    state_tag = cells_state[0].find(\"a\") or cells_state[0]\n",
    "    state = state_tag.text.strip()\n",
    "\n",
    "    #find # stores in 2023\n",
    "    stores_2023_tag = cells_obs[0].find(\"td\") or cells_obs[0]\n",
    "    stores_2023 = stores_2023_tag.text.strip()\n",
    "\n",
    "    #find # stores in 2023\n",
    "    stores_2021_tag = cells_obs[1].find(\"td\") or cells_obs[1]\n",
    "    stores_2021 = stores_2021_tag.text.strip()\n",
    "\n",
    "     #find # stores in 2023\n",
    "    stores_2024_tag = cells_obs[2].find(\"td\") or cells_obs[2]\n",
    "    stores_2024 = stores_2024_tag.text.strip()\n",
    "\n",
    "    # Append this data.\n",
    "    rows.append({\n",
    "            \"state\": state,\n",
    "            \"2023\": stores_2023,\n",
    "            \"2021\": stores_2021,\n",
    "            \"2024\": stores_2024\n",
    "     })\n",
    "\n",
    "\n",
    "sb_df = pd.DataFrame(rows)\n",
    "sb_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 (DUNKIN DONUTS)\n",
    "#requests\n",
    "dd_response = requests.get(\"https://worldpopulationreview.com/state-rankings/dunkin-donuts-by-state\")\n",
    "\n",
    "#soup\n",
    "dd_soup = BeautifulSoup(dd_response.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table (dont want table to be a list)\n",
    "dd_table = dd_soup.find(\"table\",\n",
    "                    attrs={\n",
    "                      \"class\": \"wpr-table\"}\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>2024</th>\n",
       "      <th>2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>1,431</td>\n",
       "      <td>1,414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1,042</td>\n",
       "      <td>1,068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>909</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>872</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>711</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           state   2024   2023\n",
       "0       New York  1,431  1,414\n",
       "1  Massachusetts  1,042  1,068\n",
       "2        Florida    909    883\n",
       "3     New Jersey    872    866\n",
       "4       Illinois    711    692"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn html into actual dataframe\n",
    "\n",
    "# initialize an empty list\n",
    "rows = []\n",
    "\n",
    "# iterate over all rows in the city table\n",
    "#we do 1: b/c there is only 1 header row in this data\n",
    "for state in dd_table.find_all(\"tr\")[1:]:\n",
    "\n",
    "    # Get all the cells (<th>) and (<td>) in the row.\n",
    "    cells_state = state.find_all(\"th\")\n",
    "    cells_obs = state.find_all(\"td\")\n",
    "    \n",
    "    # Find the the name of the state in cell[0]\n",
    "    # which for most state is contained in the <a> tag\n",
    "    state_tag = cells_state[0].find(\"a\") or cells_state[0]\n",
    "    state = state_tag.text.strip()\n",
    "\n",
    "    #find # stores in 2024\n",
    "    stores_2024_tag = cells_obs[0].find(\"td\") or cells_obs[0]\n",
    "    stores_2024 = stores_2024_tag.text.strip()\n",
    "\n",
    "    #find # stores in 2023\n",
    "    stores_2023_tag = cells_obs[1].find(\"td\") or cells_obs[1]\n",
    "    stores_2023 = stores_2023_tag.text.strip()\n",
    "\n",
    "\n",
    "    # Append this data.\n",
    "    rows.append({\n",
    "            \"state\": state,\n",
    "            \"2024\": stores_2024,\n",
    "            \"2023\": stores_2023\n",
    "     })\n",
    "\n",
    "\n",
    "dd_df = pd.DataFrame(rows)\n",
    "dd_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. setup data\n",
    "#will want to pivot for year and val because they are not fully overlap\n",
    "\n",
    "#Starbucks\n",
    "#pivot long, vars will be year to val\n",
    "sb_long = pd.melt(sb_df, id_vars='state', value_vars=['2021', '2023', '2024'], var_name = 'year', value_name = 'num_stores')\n",
    "\n",
    "#create brand var so that we know which store the obs is for\n",
    "sb_long['Brand'] = 'Starbucks'\n",
    "\n",
    "\n",
    "#Dunkin Donut\n",
    "#pivot long\n",
    "#pivot long, vars will be year to val\n",
    "dd_long = pd.melt(dd_df, id_vars='state', value_vars=['2023', '2024'], var_name = 'year', value_name = 'num_stores')\n",
    "\n",
    "#create brand var so that we know which store the obs is for\n",
    "dd_long['Brand'] = 'Dunkin Donut'\n",
    "\n",
    "#stack data using concat\n",
    "df_stacked = pd.concat([sb_long, dd_long], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supplemental Data**\n",
    "\n",
    "4. Scrape the state names and populations from this wikipedia page. Merge these data with your coffee dataset.\n",
    "\n",
    "5. Find the revenue, stock price, or your financial metric of choice for each of the companies listed above (if you can find a website to scrape these from that’s great!…but it’s okay if you manually enter these). Merge these values into your big dataset. Note: these values may be repeated for each state.\n",
    "\n",
    "6. Create a region variable in your dataset according to the scheme on this wikipedia page: Northeast, Midwest, South, West. You do not need to scrape this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 (wikipedia)\n",
    "#requests\n",
    "wiki_response = requests.get(\"https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population\")\n",
    "\n",
    "#soup\n",
    "wiki_soup = BeautifulSoup(wiki_response.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = wiki_soup.find_all(\"table\")\n",
    "len(tables)\n",
    "#turn into just non-list\n",
    "wiki_table = tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOESNT WORK, LINE ABOVE DOES\n",
    "#table (dont want table to be a list)\n",
    "#wiki_table = wiki_soup.find(\"table\",\n",
    "                    #attrs={\n",
    "                      #\"class\": \"wikitable sortable jquery-tablesorter\"}\n",
    "                  #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>census_2020</th>\n",
       "      <th>census_2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>39,538,223</td>\n",
       "      <td>37,253,956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>30,145,505</td>\n",
       "      <td>25,145,561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>21,538,187</td>\n",
       "      <td>18,801,310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "      <td>20,201,249</td>\n",
       "      <td>19,378,102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>13,002,700</td>\n",
       "      <td>12,702,379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          state census_2020 census_2010\n",
       "0    California  39,538,223  37,253,956\n",
       "1         Texas  30,145,505  25,145,561\n",
       "2       Florida  21,538,187  18,801,310\n",
       "3      New York  20,201,249  19,378,102\n",
       "4  Pennsylvania  13,002,700  12,702,379"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn html into actual dataframe\n",
    "\n",
    "# initialize an empty list\n",
    "rows = []\n",
    "\n",
    "# iterate over all rows in the city table\n",
    "#we do 1: b/c there is only 1 header row in this data\n",
    "for state in wiki_table.find_all(\"tr\")[1:]:\n",
    "\n",
    "    # Get all the cells (<td>) in the row.\n",
    "    cells = state.find_all(\"td\")\n",
    "    \n",
    "    # can just look at table and see what obs we want along and pick that indexes b/c its in a weirdish order\n",
    "    state_tag = cells[2]\n",
    "    state = state_tag.text.strip()\n",
    "\n",
    "    #find # stores in 2024\n",
    "    census_2020_tag = cells[3]\n",
    "    census_2020 = census_2020_tag.text.strip()\n",
    "\n",
    "    #find # stores in 2023\n",
    "    census_2010_tag = cells[4]\n",
    "    census_2010 = census_2010_tag.text.strip()\n",
    "\n",
    "\n",
    "    # Append this data.\n",
    "    rows.append({\n",
    "            \"state\": state,\n",
    "            \"census_2020\": census_2020,\n",
    "            \"census_2010\": census_2010\n",
    "     })\n",
    "\n",
    "\n",
    "wiki_df = pd.DataFrame(rows)\n",
    "wiki_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge this wiki_df to our df_stacked with id as state\n",
    "#use outer to ensure we don't lose any data (can change that later if we need to)\n",
    "merged_df = pd.merge(wiki_df, df_stacked, how='outer', on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IS IT OKAY IF REVENUE ISN'T BY YEAR?\n",
    "#5.\n",
    "#I had chat GPT make an example dataframe of total revenue (where it is adjusted by population)\n",
    "# Here is the code directly copied that it gave me:\n",
    "\n",
    "#will be the same regardless of year\n",
    "#so this dataframe displays the brand's overall revenue per state\n",
    "\n",
    "# List of all states\n",
    "states = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', \n",
    "          'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', \n",
    "          'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', \n",
    "          'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', \n",
    "          'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', \n",
    "          'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', \n",
    "          'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', \n",
    "          'Wisconsin', 'Wyoming']\n",
    "\n",
    "# Adjusted revenue data for Starbucks (based on larger population and presence)\n",
    "starbucks_revenue = [600, 50, 550, 180, 2500, 800, 400, 150, 1600, 1300, 100, 120, 1100, 700, 350,\n",
    "                     300, 500, 420, 80, 750, 1400, 900, 600, 200, 550, 90, 150, 300, 120, 850,\n",
    "                     180, 1800, 1300, 80, 1100, 250, 550, 1100, 90, 480, 100, 950, 2100, 250, \n",
    "                     90, 900, 1600, 150, 800, 40]\n",
    "\n",
    "sb_revenue = pd.DataFrame({\n",
    "    'state': states,\n",
    "    'revenue': starbucks_revenue})\n",
    "\n",
    "sb_revenue['Brand'] = 'Starbucks'\n",
    "\n",
    "# Adjusted revenue data for Dunkin' Donuts (stronger presence in the Northeast)\n",
    "dunkin_donuts_revenue = [150, 10, 100, 80, 300, 150, 450, 80, 500, 300, 20, 60, 450, 250, 80,\n",
    "                         100, 200, 180, 50, 400, 1200, 500, 250, 80, 220, 40, 80, 150, 90, 700,\n",
    "                         120, 1000, 500, 30, 600, 120, 150, 700, 80, 220, 60, 400, 800, 120, \n",
    "                         30, 500, 700, 90, 400, 20]\n",
    "\n",
    "dd_revenue = pd.DataFrame({\n",
    "    'state': states,\n",
    "    'revenue': dunkin_donuts_revenue})\n",
    "\n",
    "dd_revenue['Brand'] = 'Dunkin Donut'\n",
    "\n",
    "#stack data using concat\n",
    "revenue_stacked = pd.concat([sb_revenue, dd_revenue], axis=0, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with our merged_df\n",
    "#use outer to ensure we don't lose any data (can change that later if we need to)\n",
    "merged_df = pd.merge(merged_df, revenue_stacked, how='outer', on=['state', 'Brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.\n",
    "#used chat GPT to automate this part of the task\n",
    "#lists all the states with their corresponding region\n",
    "regions = {\n",
    "    \"Northeast\": [\"Connecticut\", \"Maine\", \"Massachusetts\", \"New Hampshire\", \"Rhode Island\", \"Vermont\", \"New Jersey\", \"New York\", \"Pennsylvania\"],\n",
    "    \"Midwest\": [\"Illinois\", \"Indiana\", \"Michigan\", \"Ohio\", \"Wisconsin\", \"Iowa\", \"Kansas\", \"Minnesota\", \"Missouri\", \"Nebraska\", \"North Dakota\", \"South Dakota\"],\n",
    "    \"South\": [\"Delaware\", \"Florida\", \"Georgia\", \"Maryland\", \"North Carolina\", \"South Carolina\", \"Virginia\", \"Washington, D.C.\", \"West Virginia\", \"Alabama\", \"Kentucky\", \"Mississippi\", \"Tennessee\", \"Arkansas\", \"Louisiana\", \"Oklahoma\", \"Texas\"],\n",
    "    \"West\": [\"Arizona\", \"Colorado\", \"Idaho\", \"Montana\", \"Nevada\", \"New Mexico\", \"Utah\", \"Wyoming\", \"Alaska\", \"California\", \"Hawaii\", \"Oregon\", \"Washington\"]\n",
    "}\n",
    "\n",
    "# creates df so that it will be easy to merge the data\n",
    "#it creates the dataframe with state, and region. Loops for each region and then gets all the states inside it.\n",
    "# For each state its creating a \"tuple\" where the first element is the state and the second is the region\n",
    "region_df = pd.DataFrame([(state, region) for region, states in regions.items() for state in states], columns=['state', 'region'])\n",
    "\n",
    "\n",
    "#Merge with merged_df on state\n",
    "final_df = pd.merge(merged_df, region_df, how='outer', on=['state'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
